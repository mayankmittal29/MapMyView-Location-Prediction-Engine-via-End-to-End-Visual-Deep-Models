# ğŸ—ºï¸ MapMyView: See Where You Stand Instantly ğŸŒ

[![made-with-python](https://img.shields.io/badge/Made%20with-Python-1f425f.svg)](https://www.python.org/)
[![made-with-react](https://img.shields.io/badge/Made%20with-React-61DAFB.svg)](https://reactjs.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.95.1-009688.svg)](https://fastapi.tiangolo.com/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0.0-EE4C2C.svg)](https://pytorch.org/)

## ğŸ“‹ Table of Contents
- [Project Overview](#-project-overview)
- [Architecture & Models](#-architecture--models)
- [Directory Structure](#-directory-structure)
- [Tech Stack](#-tech-stack)
- [Installation & Setup](#-installation--setup)
- [API Endpoints](#-api-endpoints)
- [Frontend Features](#-frontend-features)
- [Model Performance](#-model-performance)
- [Future Improvements](#-future-improvements)

## ğŸŒŸ Project Overview

**MapMyView** is an advanced location recognition system designed to identify campus regions, precise geographic coordinates, and camera orientation from user-submitted images. Using state-of-the-art deep learning models, the system processes images in real-time to return:

- ğŸ™ï¸ **Region ID**: Identifies specific campus areas from 15 distinct regions
- ğŸ“ **Latitude/Longitude**: Provides precise geographic positioning
- ğŸ§­ **Angle**: Determines the camera orientation angle (0-360Â°)

This project leverages multiple specialized neural networks for accurate spatial awareness, making it perfect for campus navigation, tour guides, educational applications, and geolocation verification systems.
![RegionM Map](regionmap.png)
## ğŸ§  Architecture & Models

MapMyView employs a sophisticated multi-model architecture, each trained for specific tasks:

### 1ï¸âƒ£ Region Classification Model

- ğŸ” **Architecture**: Fine-tuned ConvNeXt Small with custom classification head
- ğŸ§© **Features**:
  - Transfer learning with ImageNet pre-trained weights
  - Early layer freezing to prevent overfitting
  - Advanced classifier with LayerNorm, GELU activations, and strategic dropout
  - 15-class output for precise region identification
- ğŸ“ˆ **Performance**: 96.75% validation accuracy

### 2ï¸âƒ£ Geographic Coordinate Prediction Model


- ğŸ” **Architecture**: Swin Transformer (`swin_base_patch4_window7_224`) with dual regression heads
- ğŸ§© **Features**:
  - Hierarchical feature fusion with dimension reduction (1024â†’512)
  - Separate specialized prediction pathways for latitude and longitude
  - Coordinate standardization for improved training stability
  - Anomaly filtering for cleaner validation data
- ğŸ“ˆ **Performance**: High-precision geographic coordinates with normalized MSE

### 3ï¸âƒ£ Angle Prediction Model


- ğŸ” **Architecture**: EfficientNet B0 with circular regression approach
- ğŸ§© **Features**:
  - Predicts sine/cosine components instead of direct angles
  - Unit circle normalization for consistent angle reconstruction
  - Angular-aware data augmentation preserving circular properties
  - Exponential Moving Average for improved stability
- ğŸ“ˆ **Performance**: Mean Absolute Angular Error (MAAE) of 27Â°

## ğŸ“ Directory Structure

```
MapMyView/
â”œâ”€â”€ ğŸ“„ main.py              # FastAPI server implementation
â”œâ”€â”€ ğŸ“„ requirements.txt     # Python dependencies
â”œâ”€â”€ ğŸ“‚ Models/        # Model weights and data files
â”‚   â”œâ”€â”€ ğŸ“„ region_final.pth              # Region classifier weights
â”‚   â”œâ”€â”€ ğŸ“„ latlong_only_images_final_22.pth # Lat/Long model weights
â”‚   â”œâ”€â”€ ğŸ“„ angle_final_only_images_27.pt # Angle predictor weights
â”‚   â””â”€â”€ ğŸ“„ cleaned_data_train.csv        # Training data statistics
â”œâ”€â”€ ğŸ“‚ frontend/            # React frontend application
â”‚   â”œâ”€â”€ ğŸ“„ package.json     # NPM dependencies
â”‚   â”œâ”€â”€ ğŸ“‚ public/          # Static assets including maps
â”‚   â”‚   â””â”€â”€ ğŸ“„ regionmap.png     # Campus region map
â”‚   â””â”€â”€ ğŸ“‚ src/             # React source code
â”‚       â”œâ”€â”€ ğŸ“„ App.js       # Main application component
â”‚       â””â”€â”€ ğŸ“„ App.css      # Application styling
```

## ğŸ› ï¸ Tech Stack

### Backend Technologies
- ğŸ **Python 3.9+**: Core programming language
- âš¡ **FastAPI**: High-performance API framework
- ğŸ”¥ **PyTorch**: Deep learning framework
- ğŸ§® **Timm**: PyTorch Image Models library
- ğŸ–¼ï¸ **Pillow**: Image processing
- ğŸ”¢ **Pandas**: Data manipulation

### Frontend Technologies
- âš›ï¸ **React**: User interface library
- ğŸŒ **Axios**: HTTP client for API requests
- ğŸ¨ **CSS3**: Custom styling and responsive design

### Deep Learning Components
- ğŸ§  **ConvNeXt**: Advanced convolutional architecture for region classification
- ğŸ” **Swin Transformer**: Vision transformer for coordinate prediction
- ğŸ“Š **EfficientNet**: Efficient CNN for angle prediction
- ğŸ“ **Circular Regression**: Specialized approach for angle prediction

## ğŸš€ Installation & Setup

### Backend Setup

1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/MapMyView.git
   cd MapMyView
   ```

2. Create and activate a virtual environment:
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

4. Download model weights and place them in the `Models` directory:
   - `region_final.pth`
   - `latlong_only_images_final_22.pth`
   - `angle_final_only_images_27.pt`

5. Run the FastAPI server:
   ```bash
   uvicorn main:app --reload
   ```

### Frontend Setup

1. Navigate to the frontend directory:
   ```bash
   cd frontend
   ```

2. Install dependencies:
   ```bash
   npm install
   ```

3. Start the development server:
   ```bash
   npm start
   ```

4. The application will be available at `http://localhost:3000`

## ğŸ”Œ API Endpoints

### `/predict/` (POST)
- **Function**: Process an image and return region, coordinates, and angle predictions
- **Input**: Image file (multipart/form-data)
- **Output**: JSON with the following structure:
  ```json
  {
    "Region_ID": 5,
    "latitude": 17.445923,
    "longitude": 78.348721,
    "angle": 157.24
  }
  ```

## ğŸ’» Frontend Features
![View](homepage.png)
- ğŸ“¤ **Image Upload**: Intuitive file selection interface
- ğŸ‘ï¸ **Image Preview**: Visual feedback before prediction
- ğŸš€ **One-Click Prediction**: Simple prediction initiation
- ğŸ”„ **Clear Function**: Reset the application state
- ğŸ—ºï¸ **Region Map**: Visual reference for region IDs
- ğŸ“Š **Result Display**: Clear presentation of prediction outcomes

## ğŸ“Š Model Performance

### Region Classification
- **Accuracy**: 96.75% on validation set
- **Training**: Mixed precision with CosineAnnealingWarmRestarts scheduler
- **Regularization**: Strategic dropout and label smoothing (0.15)

### Latitude/Longitude Prediction
- **MSE**: ~22,000 unscaled MSE
- **Training**: OneCycleLR with separate learning rates for backbone and heads
- **Optimization**: AdamW with weight decay (1e-2)

### Angle Prediction
- **MAAE**: 27Â° mean absolute angular error
- **Training**: Circular regression with composite loss function
- **Techniques**: Exponential Moving Average (decay=0.998)

## ğŸ”® Future Improvements

- ğŸŒ **Global Positioning**: Extend beyond campus to wider geographic areas
- ğŸ“± **Mobile Application**: Develop native mobile versions for Android and iOS
- ğŸ”„ **Real-Time Processing**: Implement video stream processing
- ğŸ§  **Ensemble Methods**: Combine multiple models for even higher accuracy
- ğŸŒ¦ï¸ **Weather Robustness**: Improve performance under varying weather conditions
- ğŸ¯ **Point-of-Interest Detection**: Add landmark identification
- ğŸ”’ **Edge Deployment**: Move processing to edge devices for privacy

---

## ğŸ‘¨â€ğŸ’» Project Contributors

- **Mayank Mittal** - *Primary Developer* - [GitHub](https://github.com/mayankmittal29)


<p align="center">
  Made with â¤ï¸ for IIIT Hyderabad Campus
</p>
