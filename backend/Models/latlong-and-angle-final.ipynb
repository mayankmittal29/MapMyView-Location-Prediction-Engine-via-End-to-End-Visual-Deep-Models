{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final code for Latitude and Longitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using only images for training and not Region_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T09:00:13.040391Z",
     "iopub.status.busy": "2025-05-05T09:00:13.039848Z",
     "iopub.status.idle": "2025-05-05T09:56:16.600258Z",
     "shell.execute_reply": "2025-05-05T09:56:16.599394Z",
     "shell.execute_reply.started": "2025-05-05T09:00:13.040364Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Original valid_df size: 362\n",
      "VALID_IMG_DIR exists: True\n",
      "TEST_IMG_DIR exists: True\n",
      "Valid image extensions: Counter({'.jpg': 246, '.jpeg': 96, '.png': 27})\n",
      "Test image extensions: Counter({'.jpg': 241, '.jpeg': 101, '.png': 27})\n",
      "Number of files in '/kaggle/input/iiith-images-latlong-smai/images_test/images_test': 369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31/3891777002.py:170: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler() if torch.cuda.is_available() else None\n",
      "Epoch 1 Train:   0%|          | 0/405 [00:00<?, ?it/s]/tmp/ipykernel_31/3891777002.py:186: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Epoch 1 Train: 100%|██████████| 405/405 [01:45<00:00,  3.82it/s, loss=0.00707, lat=0.000206, lon=0.00686, lr=2.07e-6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 TRAIN -> Loss: 1.476800, Lat: 0.775467, Lon: 0.701334, LR: 2.068898e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Val: 100%|██████████| 12/12 [00:05<00:00,  2.27it/s, v_loss=0.285, v_lat=0.173, v_lon=0.113]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 VAL   -> Loss: 0.910843, Lat: 0.495232, Lon: 0.415611, Unscaled MSE: 503451.937500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Train:   0%|          | 0/405 [00:00<?, ?it/s]/tmp/ipykernel_31/3891777002.py:186: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Epoch 2 Train: 100%|██████████| 405/405 [01:45<00:00,  3.83it/s, loss=0.243, lat=0.0479, lon=0.195, lr=4.57e-6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 TRAIN -> Loss: 0.901840, Lat: 0.478796, Lon: 0.423044, LR: 4.570734e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Val: 100%|██████████| 12/12 [00:05<00:00,  2.29it/s, v_loss=0.221, v_lat=0.121, v_lon=0.0997]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 VAL   -> Loss: 0.536795, Lat: 0.308611, Lon: 0.228184, Unscaled MSE: 291883.843750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Train:   0%|          | 0/405 [00:00<?, ?it/s]/tmp/ipykernel_31/3891777002.py:186: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Epoch 3 Train: 100%|██████████| 405/405 [01:45<00:00,  3.82it/s, loss=0.602, lat=0.33, lon=0.272, lr=8.4e-6]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 TRAIN -> Loss: 0.610107, Lat: 0.333673, Lon: 0.276434, LR: 8.403584e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Val: 100%|██████████| 12/12 [00:05<00:00,  2.30it/s, v_loss=0.169, v_lat=0.0817, v_lon=0.0872]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 VAL   -> Loss: 0.350837, Lat: 0.181555, Lon: 0.169281, Unscaled MSE: 196564.781250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Train:   0%|          | 0/405 [00:00<?, ?it/s]/tmp/ipykernel_31/3891777002.py:186: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Epoch 4 Train: 100%|██████████| 405/405 [01:45<00:00,  3.84it/s, loss=0.0895, lat=0.0714, lon=0.0182, lr=1.31e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 TRAIN -> Loss: 0.441012, Lat: 0.236420, Lon: 0.204592, LR: 1.310490e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Val: 100%|██████████| 12/12 [00:05<00:00,  2.31it/s, v_loss=0.13, v_lat=0.0782, v_lon=0.052]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 VAL   -> Loss: 0.397108, Lat: 0.217806, Lon: 0.179302, Unscaled MSE: 218949.031250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 Train:   0%|          | 0/405 [00:00<?, ?it/s]/tmp/ipykernel_31/3891777002.py:186: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Epoch 5 Train: 100%|██████████| 405/405 [01:45<00:00,  3.83it/s, loss=0.401, lat=0.121, lon=0.281, lr=1.81e-5]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 TRAIN -> Loss: 0.323096, Lat: 0.177709, Lon: 0.145387, LR: 1.810733e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 Val: 100%|██████████| 12/12 [00:05<00:00,  2.32it/s, v_loss=0.0705, v_lat=0.033, v_lon=0.0374]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 VAL   -> Loss: 0.353834, Lat: 0.179782, Lon: 0.174052, Unscaled MSE: 199201.125000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 Train:   0%|          | 0/405 [00:00<?, ?it/s]/tmp/ipykernel_31/3891777002.py:186: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Epoch 6 Train: 100%|██████████| 405/405 [01:45<00:00,  3.85it/s, loss=0.0997, lat=0.0315, lon=0.0682, lr=2.28e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 TRAIN -> Loss: 0.272191, Lat: 0.149808, Lon: 0.122384, LR: 2.280717e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 Val: 100%|██████████| 12/12 [00:05<00:00,  2.29it/s, v_loss=0.0499, v_lat=0.0282, v_lon=0.0217]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 VAL   -> Loss: 0.208587, Lat: 0.100095, Lon: 0.108492, Unscaled MSE: 119123.843750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 Train:   0%|          | 0/405 [00:00<?, ?it/s]/tmp/ipykernel_31/3891777002.py:186: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Epoch 7 Train: 100%|██████████| 405/405 [01:45<00:00,  3.85it/s, loss=0.0227, lat=0.00102, lon=0.0217, lr=2.66e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 TRAIN -> Loss: 0.233845, Lat: 0.130862, Lon: 0.102983, LR: 2.663724e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 Val: 100%|██████████| 12/12 [00:05<00:00,  2.30it/s, v_loss=0.0662, v_lat=0.0384, v_lon=0.0278]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 VAL   -> Loss: 0.198263, Lat: 0.092800, Lon: 0.105463, Unscaled MSE: 113901.679688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 Train:   0%|          | 0/405 [00:00<?, ?it/s]/tmp/ipykernel_31/3891777002.py:186: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Epoch 8 Train: 100%|██████████| 405/405 [01:45<00:00,  3.83it/s, loss=0.0136, lat=9.7e-6, lon=0.0136, lr=2.91e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 TRAIN -> Loss: 0.215415, Lat: 0.113046, Lon: 0.102369, LR: 2.913534e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 Val: 100%|██████████| 12/12 [00:05<00:00,  2.30it/s, v_loss=0.0456, v_lat=0.0211, v_lon=0.0245]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 VAL   -> Loss: 0.180314, Lat: 0.076507, Lon: 0.103807, Unscaled MSE: 105860.507812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 Train:   0%|          | 0/405 [00:00<?, ?it/s]/tmp/ipykernel_31/3891777002.py:186: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Epoch 9 Train: 100%|██████████| 405/405 [01:45<00:00,  3.83it/s, loss=0.00134, lat=0.000353, lon=0.000987, lr=3e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 TRAIN -> Loss: 0.144425, Lat: 0.083558, Lon: 0.060867, LR: 3.000000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 Val: 100%|██████████| 12/12 [00:05<00:00,  2.30it/s, v_loss=0.035, v_lat=0.013, v_lon=0.0221] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 VAL   -> Loss: 0.161975, Lat: 0.069518, Lon: 0.092457, Unscaled MSE: 94866.429688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 Train:   0%|          | 0/405 [00:00<?, ?it/s]/tmp/ipykernel_31/3891777002.py:186: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Epoch 10 Train: 100%|██████████| 405/405 [01:45<00:00,  3.83it/s, loss=0.00267, lat=0.00266, lon=1.57e-5, lr=2.98e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 TRAIN -> Loss: 0.139324, Lat: 0.078263, Lon: 0.061060, LR: 2.983164e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 Val: 100%|██████████| 12/12 [00:05<00:00,  2.33it/s, v_loss=0.043, v_lat=0.0209, v_lon=0.0221] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 VAL   -> Loss: 0.142734, Lat: 0.063872, Lon: 0.078862, Unscaled MSE: 82845.351562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 Train:   0%|          | 0/405 [00:00<?, ?it/s]/tmp/ipykernel_31/3891777002.py:186: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Epoch 11 Train: 100%|██████████| 405/405 [01:45<00:00,  3.84it/s, loss=0.0041, lat=0.000972, lon=0.00312, lr=2.93e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 TRAIN -> Loss: 0.118800, Lat: 0.067046, Lon: 0.051754, LR: 2.933196e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 Val: 100%|██████████| 12/12 [00:05<00:00,  2.29it/s, v_loss=0.0352, v_lat=0.0153, v_lon=0.0199]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 VAL   -> Loss: 0.160020, Lat: 0.066476, Lon: 0.093544, Unscaled MSE: 94355.015625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 Train:   0%|          | 0/405 [00:00<?, ?it/s]/tmp/ipykernel_31/3891777002.py:186: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Epoch 12 Train: 100%|██████████| 405/405 [01:45<00:00,  3.84it/s, loss=0.0894, lat=0.0548, lon=0.0346, lr=2.85e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 TRAIN -> Loss: 0.148187, Lat: 0.076779, Lon: 0.071407, LR: 2.851213e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 Val: 100%|██████████| 12/12 [00:05<00:00,  2.31it/s, v_loss=0.0317, v_lat=0.0137, v_lon=0.018] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 VAL   -> Loss: 0.188285, Lat: 0.092289, Lon: 0.095996, Unscaled MSE: 106972.265625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 Train:   0%|          | 0/405 [00:00<?, ?it/s]/tmp/ipykernel_31/3891777002.py:186: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Epoch 13 Train: 100%|██████████| 405/405 [01:45<00:00,  3.84it/s, loss=0.0387, lat=0.0374, lon=0.00132, lr=2.74e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 TRAIN -> Loss: 0.149658, Lat: 0.074119, Lon: 0.075539, LR: 2.739047e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 Val: 100%|██████████| 12/12 [00:05<00:00,  2.31it/s, v_loss=0.0448, v_lat=0.0111, v_lon=0.0337]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 VAL   -> Loss: 0.139571, Lat: 0.070005, Lon: 0.069566, Unscaled MSE: 78837.570312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 Train:   0%|          | 0/405 [00:00<?, ?it/s]/tmp/ipykernel_31/3891777002.py:186: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Epoch 14 Train: 100%|██████████| 405/405 [01:45<00:00,  3.84it/s, loss=0.0692, lat=0.0254, lon=0.0437, lr=2.6e-5]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 TRAIN -> Loss: 0.100592, Lat: 0.057300, Lon: 0.043292, LR: 2.599202e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 Val: 100%|██████████| 12/12 [00:05<00:00,  2.34it/s, v_loss=0.0276, v_lat=0.0156, v_lon=0.012]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 VAL   -> Loss: 0.114521, Lat: 0.069597, Lon: 0.044925, Unscaled MSE: 61190.121094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 Train:   0%|          | 0/405 [00:00<?, ?it/s]/tmp/ipykernel_31/3891777002.py:186: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Epoch 15 Train: 100%|██████████| 405/405 [01:45<00:00,  3.84it/s, loss=0.0147, lat=0.00116, lon=0.0136, lr=2.43e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 TRAIN -> Loss: 0.091778, Lat: 0.048726, Lon: 0.043052, LR: 2.434804e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 Val: 100%|██████████| 12/12 [00:05<00:00,  2.30it/s, v_loss=0.03, v_lat=0.0135, v_lon=0.0165]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 VAL   -> Loss: 0.089946, Lat: 0.048377, Lon: 0.041569, Unscaled MSE: 49867.691406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 Train:   0%|          | 0/405 [00:00<?, ?it/s]/tmp/ipykernel_31/3891777002.py:186: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Epoch 16 Train: 100%|██████████| 405/405 [01:45<00:00,  3.85it/s, loss=0.153, lat=0.0567, lon=0.0964, lr=2.25e-5]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 TRAIN -> Loss: 0.066839, Lat: 0.037406, Lon: 0.029433, LR: 2.249523e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 Val: 100%|██████████| 12/12 [00:05<00:00,  2.30it/s, v_loss=0.0202, v_lat=0.00986, v_lon=0.0104]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 VAL   -> Loss: 0.082579, Lat: 0.044127, Lon: 0.038452, Unscaled MSE: 45865.996094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 Train:   0%|          | 0/405 [00:00<?, ?it/s]/tmp/ipykernel_31/3891777002.py:186: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Epoch 17 Train: 100%|██████████| 405/405 [01:45<00:00,  3.84it/s, loss=0.0207, lat=0.00437, lon=0.0163, lr=2.05e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 TRAIN -> Loss: 0.067978, Lat: 0.036802, Lon: 0.031176, LR: 2.047500e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 Val: 100%|██████████| 12/12 [00:05<00:00,  2.31it/s, v_loss=0.023, v_lat=0.0102, v_lon=0.0127]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 VAL   -> Loss: 0.075182, Lat: 0.042942, Lon: 0.032240, Unscaled MSE: 40961.164062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 Train:   0%|          | 0/405 [00:00<?, ?it/s]/tmp/ipykernel_31/3891777002.py:186: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Epoch 18 Train: 100%|██████████| 405/405 [01:45<00:00,  3.84it/s, loss=0.00881, lat=0.00759, lon=0.00122, lr=1.83e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 TRAIN -> Loss: 0.057188, Lat: 0.031355, Lon: 0.025833, LR: 1.833246e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 Val: 100%|██████████| 12/12 [00:05<00:00,  2.33it/s, v_loss=0.0197, v_lat=0.0102, v_lon=0.00946]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 VAL   -> Loss: 0.102492, Lat: 0.051858, Lon: 0.050634, Unscaled MSE: 57763.777344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 Train:   0%|          | 0/405 [00:00<?, ?it/s]/tmp/ipykernel_31/3891777002.py:186: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Epoch 19 Train: 100%|██████████| 405/405 [01:45<00:00,  3.84it/s, loss=0.0194, lat=0.0066, lon=0.0128, lr=1.61e-5]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 TRAIN -> Loss: 0.051687, Lat: 0.030118, Lon: 0.021569, LR: 1.611548e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 Val: 100%|██████████| 12/12 [00:05<00:00,  2.33it/s, v_loss=0.0223, v_lat=0.0112, v_lon=0.0111] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 VAL   -> Loss: 0.092919, Lat: 0.059299, Lon: 0.033620, Unscaled MSE: 48833.664062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 Train:   0%|          | 0/405 [00:00<?, ?it/s]/tmp/ipykernel_31/3891777002.py:186: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Epoch 20 Train: 100%|██████████| 405/405 [01:45<00:00,  3.85it/s, loss=0.0166, lat=0.0157, lon=0.000876, lr=1.39e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 TRAIN -> Loss: 0.049288, Lat: 0.029561, Lon: 0.019727, LR: 1.387359e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 Val: 100%|██████████| 12/12 [00:05<00:00,  2.34it/s, v_loss=0.0214, v_lat=0.0117, v_lon=0.00968] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 VAL   -> Loss: 0.078052, Lat: 0.043843, Lon: 0.034209, Unscaled MSE: 42737.164062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21 Train:   0%|          | 0/405 [00:00<?, ?it/s]/tmp/ipykernel_31/3891777002.py:186: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Epoch 21 Train: 100%|██████████| 405/405 [01:45<00:00,  3.85it/s, loss=0.000912, lat=2.27e-5, lon=0.000889, lr=1.17e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 TRAIN -> Loss: 0.042917, Lat: 0.023103, Lon: 0.019814, LR: 1.165686e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21 Val: 100%|██████████| 12/12 [00:05<00:00,  2.31it/s, v_loss=0.0223, v_lat=0.012, v_lon=0.0103]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 VAL   -> Loss: 0.091403, Lat: 0.046715, Lon: 0.044688, Unscaled MSE: 51379.347656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22 Train:   0%|          | 0/405 [00:00<?, ?it/s]/tmp/ipykernel_31/3891777002.py:186: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Epoch 22 Train: 100%|██████████| 405/405 [01:45<00:00,  3.84it/s, loss=0.0755, lat=0.0388, lon=0.0366, lr=9.51e-6]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 TRAIN -> Loss: 0.039817, Lat: 0.022748, Lon: 0.017069, LR: 9.514809e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22 Val: 100%|██████████| 12/12 [00:05<00:00,  2.31it/s, v_loss=0.0231, v_lat=0.011, v_lon=0.012]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 VAL   -> Loss: 0.064765, Lat: 0.037179, Lon: 0.027586, Unscaled MSE: 35232.277344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23 Train:   0%|          | 0/405 [00:00<?, ?it/s]/tmp/ipykernel_31/3891777002.py:186: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Epoch 23 Train: 100%|██████████| 405/405 [01:45<00:00,  3.83it/s, loss=0.0262, lat=0.0249, lon=0.00137, lr=7.5e-6]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 TRAIN -> Loss: 0.037369, Lat: 0.021838, Lon: 0.015531, LR: 7.495292e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23 Val: 100%|██████████| 12/12 [00:05<00:00,  2.32it/s, v_loss=0.0238, v_lat=0.0131, v_lon=0.0107] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 VAL   -> Loss: 0.069874, Lat: 0.041475, Lon: 0.028399, Unscaled MSE: 37619.011719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24 Train:   0%|          | 0/405 [00:00<?, ?it/s]/tmp/ipykernel_31/3891777002.py:186: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Epoch 24 Train: 100%|██████████| 405/405 [01:45<00:00,  3.85it/s, loss=0.0659, lat=0.0333, lon=0.0326, lr=5.64e-6]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 TRAIN -> Loss: 0.033180, Lat: 0.019143, Lon: 0.014037, LR: 5.643419e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24 Val: 100%|██████████| 12/12 [00:05<00:00,  2.30it/s, v_loss=0.0213, v_lat=0.0111, v_lon=0.0102] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 VAL   -> Loss: 0.064207, Lat: 0.037987, Lon: 0.026220, Unscaled MSE: 34604.109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25 Train:   0%|          | 0/405 [00:00<?, ?it/s]/tmp/ipykernel_31/3891777002.py:186: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Epoch 25 Train: 100%|██████████| 405/405 [01:45<00:00,  3.85it/s, loss=0.0188, lat=0.00986, lon=0.00894, lr=4e-6]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 TRAIN -> Loss: 0.031124, Lat: 0.017368, Lon: 0.013757, LR: 4.000558e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25 Val: 100%|██████████| 12/12 [00:05<00:00,  2.32it/s, v_loss=0.0193, v_lat=0.0105, v_lon=0.00873]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 VAL   -> Loss: 0.056008, Lat: 0.031511, Lon: 0.024498, Unscaled MSE: 30652.966797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26 Train:   0%|          | 0/405 [00:00<?, ?it/s]/tmp/ipykernel_31/3891777002.py:186: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Epoch 26 Train: 100%|██████████| 405/405 [01:45<00:00,  3.84it/s, loss=0.000611, lat=0.000151, lon=0.00046, lr=2.6e-6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 TRAIN -> Loss: 0.029908, Lat: 0.017133, Lon: 0.012775, LR: 2.603408e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26 Val: 100%|██████████| 12/12 [00:05<00:00,  2.34it/s, v_loss=0.0196, v_lat=0.0106, v_lon=0.00906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 VAL   -> Loss: 0.060980, Lat: 0.031071, Lon: 0.029909, Unscaled MSE: 34305.394531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27 Train:   0%|          | 0/405 [00:00<?, ?it/s]/tmp/ipykernel_31/3891777002.py:186: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Epoch 27 Train: 100%|██████████| 405/405 [01:45<00:00,  3.85it/s, loss=0.054, lat=0.0469, lon=0.00704, lr=1.48e-6]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 TRAIN -> Loss: 0.028277, Lat: 0.015410, Lon: 0.012867, LR: 1.483178e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27 Val: 100%|██████████| 12/12 [00:05<00:00,  2.32it/s, v_loss=0.0202, v_lat=0.0103, v_lon=0.00988]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 VAL   -> Loss: 0.052590, Lat: 0.031156, Lon: 0.021433, Unscaled MSE: 28330.380859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28 Train:   0%|          | 0/405 [00:00<?, ?it/s]/tmp/ipykernel_31/3891777002.py:186: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Epoch 28 Train: 100%|██████████| 405/405 [01:45<00:00,  3.85it/s, loss=0.0156, lat=0.0138, lon=0.00177, lr=6.65e-7]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 TRAIN -> Loss: 0.026218, Lat: 0.014353, Lon: 0.011865, LR: 6.648931e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28 Val: 100%|██████████| 12/12 [00:05<00:00,  2.31it/s, v_loss=0.02, v_lat=0.0109, v_lon=0.0091]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 VAL   -> Loss: 0.051863, Lat: 0.030420, Lon: 0.021444, Unscaled MSE: 28027.417969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29 Train:   0%|          | 0/405 [00:00<?, ?it/s]/tmp/ipykernel_31/3891777002.py:186: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Epoch 29 Train: 100%|██████████| 405/405 [01:45<00:00,  3.83it/s, loss=0.0494, lat=0.0365, lon=0.0129, lr=1.67e-7]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 TRAIN -> Loss: 0.025703, Lat: 0.014517, Lon: 0.011185, LR: 1.668321e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29 Val: 100%|██████████| 12/12 [00:05<00:00,  2.31it/s, v_loss=0.0195, v_lat=0.0105, v_lon=0.00897]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 VAL   -> Loss: 0.050835, Lat: 0.029795, Lon: 0.021040, Unscaled MSE: 27477.873047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30 Train:   0%|          | 0/405 [00:00<?, ?it/s]/tmp/ipykernel_31/3891777002.py:186: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Epoch 30 Train: 100%|██████████| 405/405 [01:45<00:00,  3.83it/s, loss=0.00331, lat=0.0033, lon=5.1e-6, lr=1.21e-10]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 TRAIN -> Loss: 0.024597, Lat: 0.013719, Lon: 0.010878, LR: 1.210233e-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30 Val: 100%|██████████| 12/12 [00:05<00:00,  2.30it/s, v_loss=0.0195, v_lat=0.0105, v_lon=0.00895]\n",
      "/tmp/ipykernel_31/3891777002.py:271: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_geo2.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 VAL   -> Loss: 0.050950, Lat: 0.029835, Lon: 0.021115, Unscaled MSE: 27547.646484\n",
      "\n",
      "--- Starting CSV Generation ---\n",
      "Valid loader dataset size: 362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing validation data: 100%|██████████| 12/12 [00:05<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 362 validation images, added 362 unique IDs\n",
      "Found 369 files in test directory\n",
      "Detected 'img_' prefix in test files\n",
      "Created mapping for 369 test files\n",
      "Sample mapping: [{'filename': 'img_0000.jpg', 'image_id': 369}, {'filename': 'img_0001.jpg', 'image_id': 370}, {'filename': 'img_0002.jpg', 'image_id': 371}]\n",
      "Created test dataloader with 369 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test data: 100%|██████████| 12/12 [00:05<00:00,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 369 test images\n",
      "\n",
      "CSV saved with 731 rows:\n",
      "- 362 validation entries\n",
      "- 369 test entries\n",
      "- 0 placeholder entries for missing test IDs\n",
      "Best MSE: 27547.646484375\n",
      "Training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import timm\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import gc\n",
    "from collections import Counter\n",
    "\n",
    "# --------------------- Utility Functions ---------------------\n",
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "set_seed()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --------------------- Paths ---------------------\n",
    "TRAIN_IMG_DIR  = '/kaggle/input/iiith-images-latlong-smai/images_train/images_train/images_train'\n",
    "VALID_IMG_DIR  = '/kaggle/input/iiith-images-latlong-smai/images_val/images_val'\n",
    "TEST_IMG_DIR   = '/kaggle/input/iiith-images-latlong-smai/images_test/images_test'\n",
    "TRAIN_LABELS   = '/kaggle/input/iiith-images-latlong-smai/cleaned_data_train.csv'\n",
    "VALID_LABELS   = '/kaggle/input/iiith-images-latlong-smai/labels_val_updated.csv'\n",
    "OUTPUT_CSV     = 'predictions_predict2.csv'\n",
    "ANOMALIES      = [95,145,146,158,159,160,161]\n",
    "\n",
    "# --------------------- Read DataFrames ---------------------\n",
    "train_df = pd.read_csv(TRAIN_LABELS)\n",
    "valid_df = pd.read_csv(VALID_LABELS)\n",
    "valid_df['image_id'] = valid_df['filename'].apply(lambda x: int(x.split('_')[1].split('.')[0].lstrip('0') or '0'))\n",
    "valid_df = valid_df[~valid_df['image_id'].isin(ANOMALIES)].reset_index(drop=True)\n",
    "\n",
    "# --------------------- Debug: Check Dataset Sizes ---------------------\n",
    "print(f\"Original valid_df size: {len(valid_df)}\")\n",
    "\n",
    "# --------------------- Debug: Check file extensions ---------------------\n",
    "def get_file_extensions(directory):\n",
    "    extensions = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if os.path.isfile(os.path.join(directory, filename)):\n",
    "            ext = os.path.splitext(filename)[1].lower()\n",
    "            extensions.append(ext)\n",
    "    return Counter(extensions)\n",
    "\n",
    "# Test if directories exist\n",
    "print(f\"VALID_IMG_DIR exists: {os.path.exists(VALID_IMG_DIR)}\")\n",
    "print(f\"TEST_IMG_DIR exists: {os.path.exists(TEST_IMG_DIR)}\")\n",
    "\n",
    "# Only check extensions if directories exist\n",
    "if os.path.exists(VALID_IMG_DIR):\n",
    "    print(f\"Valid image extensions: {get_file_extensions(VALID_IMG_DIR)}\")\n",
    "if os.path.exists(TEST_IMG_DIR):\n",
    "    print(f\"Test image extensions: {get_file_extensions(TEST_IMG_DIR)}\")\n",
    "    \n",
    "def count_files_in_folder(folder_path):\n",
    "    return sum(1 for entry in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, entry)))\n",
    "\n",
    "# Example usage\n",
    "print(f\"Number of files in '{TEST_IMG_DIR}': {count_files_in_folder(TEST_IMG_DIR)}\")\n",
    "\n",
    "# --------------------- Scaling ---------------------\n",
    "lat_scaler = StandardScaler().fit(train_df[['latitude']])\n",
    "long_scaler = StandardScaler().fit(train_df[['longitude']])\n",
    "for df in [train_df, valid_df]:\n",
    "    df['scaled_lat'] = lat_scaler.transform(df[['latitude']])\n",
    "    df['scaled_lon'] = long_scaler.transform(df[['longitude']])\n",
    "\n",
    "# --------------------- Transforms ---------------------\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.ColorJitter(0.3,0.3,0.3,0.05),\n",
    "    transforms.RandomAffine(20, translate=(0.15,0.15), scale=(0.85,1.15)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
    "    transforms.RandomErasing(0.2, scale=(0.02,0.15), ratio=(0.3,3.3))\n",
    "])\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "# --------------------- Dataset ---------------------\n",
    "class GeoDataset(Dataset):\n",
    "    def __init__(self, img_dir, df, transform=None, is_test=False):\n",
    "        self.img_dir = img_dir\n",
    "        self.df = df.copy()\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "        self.df = self.df[self.df['filename'].apply(lambda fn: os.path.exists(os.path.join(img_dir, fn)))].reset_index(drop=True)\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = Image.open(os.path.join(self.img_dir, row['filename'])).convert('RGB')\n",
    "        x = self.transform(img)\n",
    "        if self.is_test:\n",
    "            return {'image': x, 'image_id': int(row['filename'].split('_')[1].split('.')[0].lstrip('0') or '0')}\n",
    "        return {\n",
    "            'image': x,\n",
    "            'scaled_lat': torch.tensor(row['scaled_lat'], dtype=torch.float32),\n",
    "            'scaled_lon': torch.tensor(row['scaled_lon'], dtype=torch.float32),\n",
    "            'latitude': torch.tensor(row['latitude'], dtype=torch.float32),\n",
    "            'longitude': torch.tensor(row['longitude'], dtype=torch.float32)\n",
    "        }\n",
    "\n",
    "# --------------------- DataLoaders ---------------------\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(GeoDataset(TRAIN_IMG_DIR, train_df, train_transform), batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "valid_loader = DataLoader(GeoDataset(VALID_IMG_DIR, valid_df, val_test_transform), 32, shuffle=False, num_workers=4, pin_memory=True)\n",
    "test_loader  = DataLoader(GeoDataset(TEST_IMG_DIR, valid_df, val_test_transform, is_test=True), 32, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# --------------------- Model ---------------------\n",
    "class SwinGeoWithoutRegion(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model('swin_base_patch4_window7_224', pretrained=True, num_classes=0, global_pool='avg')\n",
    "        feat = self.backbone.num_features\n",
    "        self.fuse = nn.Sequential(\n",
    "            nn.Linear(feat, 1024), nn.LayerNorm(1024), nn.GELU(), nn.Dropout(0.2),\n",
    "            nn.Linear(1024, 512), nn.LayerNorm(512), nn.GELU(), nn.Dropout(0.2)\n",
    "        )\n",
    "        self.lat_head = nn.Sequential(nn.Linear(512, 128), nn.GELU(), nn.Linear(128, 1))\n",
    "        self.lon_head = nn.Sequential(nn.Linear(512, 128), nn.GELU(), nn.Linear(128, 1))\n",
    "    def forward(self, x):\n",
    "        feats = self.backbone(x)\n",
    "        h = self.fuse(feats)\n",
    "        return self.lat_head(h).squeeze(-1), self.lon_head(h).squeeze(-1)\n",
    "\n",
    "model = SwinGeoWithoutRegion().to(device)\n",
    "\n",
    "# --------------------- Loss, Optimizer & Scheduler ---------------------\n",
    "class GeoLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "    def forward(self, pred_lat, pred_lon, true_lat, true_lon):\n",
    "        return self.mse(pred_lat, true_lat) + self.mse(pred_lon, true_lon)\n",
    "\n",
    "criterion = GeoLoss()\n",
    "params_backbone, params_new = [], []\n",
    "for name, param in model.named_parameters():\n",
    "    if 'backbone' in name:\n",
    "        params_backbone.append(param)\n",
    "    else:\n",
    "        params_new.append(param)\n",
    "\n",
    "optimizer = optim.AdamW([\n",
    "    {'params': params_backbone, 'lr': 1e-5},\n",
    "    {'params': params_new,      'lr': 2e-4}\n",
    "], weight_decay=1e-2)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=[3e-5,5e-4], steps_per_epoch=len(train_loader), epochs=30)\n",
    "\n",
    "# --------------------- Training & Evaluation ---------------------\n",
    "def train_eval():\n",
    "    best_mse = float('inf')\n",
    "    scaler = torch.cuda.amp.GradScaler() if torch.cuda.is_available() else None\n",
    "    history = {'train_loss': [], 'train_lat_loss': [], 'train_lon_loss': [],\n",
    "               'val_loss': [], 'val_lat_loss': [], 'val_lon_loss': [],\n",
    "               'val_unscaled_mse': [], 'lr': []}\n",
    "\n",
    "    for epoch in range(1, 31):\n",
    "        model.train()\n",
    "        running_loss = running_lat = running_lon = 0.0\n",
    "        count = 0\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch} Train\")\n",
    "        for batch in pbar:\n",
    "            imgs = batch['image'].to(device)\n",
    "            lat_s = batch['scaled_lat'].to(device)\n",
    "            lon_s = batch['scaled_lon'].to(device)\n",
    "            \n",
    "            # Forward pass without region ID\n",
    "            with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
    "                p_lat, p_lon = model(imgs)\n",
    "                loss = criterion(p_lat, p_lon, lat_s, lon_s)\n",
    "                lat_loss = nn.MSELoss()(p_lat, lat_s)\n",
    "                lon_loss = nn.MSELoss()(p_lon, lon_s)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            if scaler:\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            bs = imgs.size(0)\n",
    "            running_loss += loss.item() * bs\n",
    "            running_lat += lat_loss.item() * bs\n",
    "            running_lon += lon_loss.item() * bs\n",
    "            count += bs\n",
    "            lr = optimizer.param_groups[0]['lr']\n",
    "            pbar.set_postfix({'loss': loss.item(), 'lat': lat_loss.item(), 'lon': lon_loss.item(), 'lr': lr})\n",
    "\n",
    "        epoch_loss = running_loss / count\n",
    "        epoch_lat = running_lat / count\n",
    "        epoch_lon = running_lon / count\n",
    "        history['train_loss'].append(epoch_loss)\n",
    "        history['train_lat_loss'].append(epoch_lat)\n",
    "        history['train_lon_loss'].append(epoch_lon)\n",
    "        history['lr'].append(lr)\n",
    "        print(f\"Epoch {epoch} TRAIN -> Loss: {epoch_loss:.6f}, Lat: {epoch_lat:.6f}, Lon: {epoch_lon:.6f}, LR: {lr:.6e}\")\n",
    "\n",
    "        model.eval()\n",
    "        v_loss = v_lat = v_lon = 0.0\n",
    "        v_count = 0\n",
    "        all_preds, all_true = [], []\n",
    "        vbar = tqdm(valid_loader, desc=f\"Epoch {epoch} Val\")\n",
    "        with torch.no_grad():\n",
    "            for batch in vbar:\n",
    "                imgs = batch['image'].to(device)\n",
    "                \n",
    "                # Forward pass without region ID\n",
    "                p_lat, p_lon = model(imgs)\n",
    "                lat_s = batch['scaled_lat'].to(device)\n",
    "                lon_s = batch['scaled_lon'].to(device)\n",
    "\n",
    "                loss = criterion(p_lat, p_lon, lat_s, lon_s)\n",
    "                lat_loss = nn.MSELoss()(p_lat, lat_s)\n",
    "                lon_loss = nn.MSELoss()(p_lon, lon_s)\n",
    "\n",
    "                ulat = lat_scaler.inverse_transform(p_lat.cpu().numpy().reshape(-1,1)).flatten()\n",
    "                ulon = long_scaler.inverse_transform(p_lon.cpu().numpy().reshape(-1,1)).flatten()\n",
    "                all_preds.append(np.vstack([ulat, ulon]).T)\n",
    "                tr_lat = batch['latitude'].numpy()\n",
    "                tr_lon = batch['longitude'].numpy()\n",
    "                all_true.append(np.vstack([tr_lat, tr_lon]).T)\n",
    "\n",
    "                bs = imgs.size(0)\n",
    "                v_loss += loss.item() * bs\n",
    "                v_lat += lat_loss.item() * bs\n",
    "                v_lon += lon_loss.item() * bs\n",
    "                v_count += bs\n",
    "                vbar.set_postfix({'v_loss': loss.item(), 'v_lat': lat_loss.item(), 'v_lon': lon_loss.item()})\n",
    "\n",
    "        val_loss = v_loss / v_count\n",
    "        val_lat = v_lat / v_count\n",
    "        val_lon = v_lon / v_count\n",
    "        preds = np.concatenate(all_preds)\n",
    "        true  = np.concatenate(all_true)\n",
    "        unscaled_mse = ((preds - true)**2).mean()\n",
    "\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_lat_loss'].append(val_lat)\n",
    "        history['val_lon_loss'].append(val_lon)\n",
    "        history['val_unscaled_mse'].append(unscaled_mse)\n",
    "\n",
    "        print(f\"Epoch {epoch} VAL   -> Loss: {val_loss:.6f}, Lat: {val_lat:.6f}, Lon: {val_lon:.6f}, Unscaled MSE: {unscaled_mse:.6f}\")\n",
    "\n",
    "        if unscaled_mse < best_mse:\n",
    "            best_mse = unscaled_mse\n",
    "            torch.save(model.state_dict(), 'best_geo2.pth')\n",
    "\n",
    "        torch.cuda.empty_cache(); gc.collect()\n",
    "\n",
    "    model.load_state_dict(torch.load('best_geo2.pth'))\n",
    "    return history\n",
    "\n",
    "def generate_csv(best_mse):\n",
    "    rows = []\n",
    "    model.eval()\n",
    "    \n",
    "    # Create a list to track processed IDs to avoid duplicates\n",
    "    processed_ids = set()\n",
    "    \n",
    "    print(\"\\n--- Starting CSV Generation ---\")\n",
    "    print(f\"Valid loader dataset size: {len(valid_loader.dataset)}\")\n",
    "    \n",
    "    # Process validation data with more detailed tracking\n",
    "    valid_count = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(valid_loader, desc=\"Processing validation data\"):\n",
    "            imgs = batch['image'].to(device)\n",
    "            \n",
    "            # Forward pass without region ID\n",
    "            p_lat, p_lon = model(imgs)\n",
    "            ulat = lat_scaler.inverse_transform(p_lat.cpu().numpy().reshape(-1,1)).flatten()\n",
    "            ulon = long_scaler.inverse_transform(p_lon.cpu().numpy().reshape(-1,1)).flatten()\n",
    "            \n",
    "            # Process each image in the batch\n",
    "            batch_size = imgs.size(0)\n",
    "            for i in range(batch_size):\n",
    "                if i + valid_count >= len(valid_loader.dataset):\n",
    "                    continue\n",
    "                    \n",
    "                # Get the image ID\n",
    "                image_id = valid_loader.dataset.df.iloc[valid_count + i]['image_id']\n",
    "                \n",
    "                # Check if we've already processed this ID\n",
    "                if image_id in processed_ids:\n",
    "                    print(f\"Warning: Duplicate ID {image_id} in validation data\")\n",
    "                    continue\n",
    "                    \n",
    "                processed_ids.add(image_id)\n",
    "                rows.append({\n",
    "                    'id': image_id, \n",
    "                    'Latitude': ulat[i], \n",
    "                    'Longitude': ulon[i]\n",
    "                })\n",
    "            \n",
    "            valid_count += batch_size\n",
    "    \n",
    "    print(f\"Processed {valid_count} validation images, added {len(processed_ids)} unique IDs\")\n",
    "    \n",
    "    # Process test data (IDs 369–737)\n",
    "    test_start_id = 369\n",
    "    test_end_id = 737\n",
    "    test_count = 0\n",
    "    \n",
    "    # Check if test directory exists and list files\n",
    "    if os.path.exists(TEST_IMG_DIR):\n",
    "        test_files = sorted(os.listdir(TEST_IMG_DIR))\n",
    "        print(f\"Found {len(test_files)} files in test directory\")\n",
    "        \n",
    "        # Create a list to hold test file information\n",
    "        test_file_list = []\n",
    "        \n",
    "        # Check if files have 'img_' prefix\n",
    "        if test_files and any(fn.startswith('img_') for fn in test_files):\n",
    "            print(\"Detected 'img_' prefix in test files\")\n",
    "            \n",
    "            # Map test files to test IDs sequentially\n",
    "            for i, filename in enumerate(test_files):\n",
    "                if i < (test_end_id - test_start_id + 1):  # Ensure we don't exceed the test ID range\n",
    "                    test_id = test_start_id + i\n",
    "                    test_file_list.append({\n",
    "                        'filename': filename,\n",
    "                        'image_id': test_id\n",
    "                    })\n",
    "            \n",
    "            print(f\"Created mapping for {len(test_file_list)} test files\")\n",
    "            if len(test_file_list) > 0:\n",
    "                print(f\"Sample mapping: {test_file_list[:3]}\")\n",
    "    else:\n",
    "        print(f\"Test directory {TEST_IMG_DIR} not found\")\n",
    "        test_file_list = []\n",
    "    \n",
    "    # Process test images if we have any\n",
    "    if test_file_list:\n",
    "        # Define a dataset for test images\n",
    "        class TestImageDataset(Dataset):\n",
    "            def __init__(self, img_dir, file_list, transform):\n",
    "                self.img_dir = img_dir\n",
    "                self.file_list = file_list\n",
    "                self.transform = transform\n",
    "                \n",
    "            def __len__(self):\n",
    "                return len(self.file_list)\n",
    "                \n",
    "            def __getitem__(self, idx):\n",
    "                file_info = self.file_list[idx]\n",
    "                img_path = os.path.join(self.img_dir, file_info['filename'])\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "                return {\n",
    "                    'image': self.transform(img),\n",
    "                    'image_id': file_info['image_id']\n",
    "                }\n",
    "        \n",
    "        # Create test dataset and dataloader\n",
    "        test_dataset = TestImageDataset(TEST_IMG_DIR, test_file_list, val_test_transform)\n",
    "        test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "        \n",
    "        print(f\"Created test dataloader with {len(test_dataset)} images\")\n",
    "        \n",
    "        # Process test data\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(test_dataloader, desc=\"Processing test data\"):\n",
    "                imgs = batch['image'].to(device)\n",
    "                image_ids = batch['image_id'].tolist()  # Convert tensor to list\n",
    "                \n",
    "                # Forward pass without region ID\n",
    "                p_lat, p_lon = model(imgs)\n",
    "                ulat = lat_scaler.inverse_transform(p_lat.cpu().numpy().reshape(-1,1)).flatten()\n",
    "                ulon = long_scaler.inverse_transform(p_lon.cpu().numpy().reshape(-1,1)).flatten()\n",
    "                \n",
    "                for i in range(len(image_ids)):\n",
    "                    img_id = image_ids[i]\n",
    "                    \n",
    "                    # Check if we've already processed this ID\n",
    "                    if img_id in processed_ids:\n",
    "                        print(f\"Warning: Duplicate ID {img_id} in test data\")\n",
    "                        continue\n",
    "                        \n",
    "                    processed_ids.add(img_id)\n",
    "                    rows.append({\n",
    "                        'id': img_id, \n",
    "                        'Latitude': ulat[i], \n",
    "                        'Longitude': ulon[i]\n",
    "                    })\n",
    "                    test_count += 1\n",
    "        \n",
    "        print(f\"Processed {test_count} test images\")\n",
    "    \n",
    "    # Handle any missing test IDs (fill with zeros or nearest neighbor)\n",
    "    missing_test_ids = set(range(test_start_id, test_end_id + 1)) - processed_ids\n",
    "    if missing_test_ids:\n",
    "        print(f\"Warning: {len(missing_test_ids)} test IDs missing. Adding placeholders.\")\n",
    "        for img_id in missing_test_ids:\n",
    "            rows.append({\n",
    "                'id': img_id,\n",
    "                'Latitude': 0.0,  # Use a default or interpolate from nearest neighbors\n",
    "                'Longitude': 0.0\n",
    "            })\n",
    "    \n",
    "    # Save CSV\n",
    "    result_df = pd.DataFrame(rows).sort_values('id')\n",
    "    result_df.to_csv(OUTPUT_CSV, index=False)\n",
    "    \n",
    "    print(f\"\\nCSV saved with {len(result_df)} rows:\")\n",
    "    print(f\"- {len(processed_ids.intersection(set(range(0, test_start_id))))} validation entries\")\n",
    "    print(f\"- {len(processed_ids.intersection(set(range(test_start_id, test_end_id + 1))))} test entries\")\n",
    "    print(f\"- {len(missing_test_ids)} placeholder entries for missing test IDs\")\n",
    "    \n",
    "    # Report best MSE\n",
    "    if isinstance(best_mse, dict):\n",
    "        best_mse_value = best_mse.get('val_unscaled_mse', [-1])[-1] if 'val_unscaled_mse' in best_mse else \"N/A\"\n",
    "        print(f\"Best MSE: {best_mse_value}\")\n",
    "    else:\n",
    "        print(f\"Best MSE: {best_mse:.6f}\")\n",
    "            \n",
    "# --------------------- Main ---------------------\n",
    "best_mse = train_eval()\n",
    "generate_csv(best_mse)\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning for more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T10:06:06.047464Z",
     "iopub.status.busy": "2025-05-05T10:06:06.046607Z",
     "iopub.status.idle": "2025-05-05T10:43:21.415081Z",
     "shell.execute_reply": "2025-05-05T10:43:21.414283Z",
     "shell.execute_reply.started": "2025-05-05T10:06:06.047427Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31/2636405055.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('/kaggle/working/best_geo2.pth'))\n",
      "/tmp/ipykernel_31/2636405055.py:17: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler() if torch.cuda.is_available() else None\n",
      "Retrain Epoch 1:   0%|          | 0/405 [00:00<?, ?it/s]/tmp/ipykernel_31/2636405055.py:37: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Retrain Epoch 1: 100%|██████████| 405/405 [01:45<00:00,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 1 Train Loss: 0.028745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 1 Val Loss: 0.067705, Unscaled MSE: 37737.519531\n",
      "New best model saved with MSE: 37737.519531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 2:   0%|          | 0/405 [00:00<?, ?it/s]/tmp/ipykernel_31/2636405055.py:37: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Retrain Epoch 2: 100%|██████████| 405/405 [01:45<00:00,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 2 Train Loss: 0.026634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 2 Val Loss: 0.052268, Unscaled MSE: 28238.128906\n",
      "New best model saved with MSE: 28238.128906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 3:   0%|          | 0/405 [00:00<?, ?it/s]/tmp/ipykernel_31/2636405055.py:37: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Retrain Epoch 3: 100%|██████████| 405/405 [01:45<00:00,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 3 Train Loss: 0.024891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 3 Val Loss: 0.054874, Unscaled MSE: 30919.587891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 4:   0%|          | 0/405 [00:00<?, ?it/s]/tmp/ipykernel_31/2636405055.py:37: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Retrain Epoch 4: 100%|██████████| 405/405 [01:45<00:00,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 4 Train Loss: 0.023314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 4 Val Loss: 0.049093, Unscaled MSE: 26863.105469\n",
      "New best model saved with MSE: 26863.105469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 5:   0%|          | 0/405 [00:00<?, ?it/s]/tmp/ipykernel_31/2636405055.py:37: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Retrain Epoch 5: 100%|██████████| 405/405 [01:45<00:00,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 5 Train Loss: 0.021386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 5 Val Loss: 0.048936, Unscaled MSE: 26670.064453\n",
      "New best model saved with MSE: 26670.064453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 6:   0%|          | 0/405 [00:00<?, ?it/s]/tmp/ipykernel_31/2636405055.py:37: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Retrain Epoch 6: 100%|██████████| 405/405 [01:45<00:00,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 6 Train Loss: 0.025166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 6 Val Loss: 0.065952, Unscaled MSE: 37581.089844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 7:   0%|          | 0/405 [00:00<?, ?it/s]/tmp/ipykernel_31/2636405055.py:37: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Retrain Epoch 7: 100%|██████████| 405/405 [01:45<00:00,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 7 Train Loss: 0.025610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 7 Val Loss: 0.055263, Unscaled MSE: 31331.394531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 8:   0%|          | 0/405 [00:00<?, ?it/s]/tmp/ipykernel_31/2636405055.py:37: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Retrain Epoch 8: 100%|██████████| 405/405 [01:45<00:00,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 8 Train Loss: 0.023573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 8 Val Loss: 0.047829, Unscaled MSE: 26281.480469\n",
      "New best model saved with MSE: 26281.480469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 9:   0%|          | 0/405 [00:00<?, ?it/s]/tmp/ipykernel_31/2636405055.py:37: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Retrain Epoch 9: 100%|██████████| 405/405 [01:45<00:00,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 9 Train Loss: 0.020808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 9 Val Loss: 0.045826, Unscaled MSE: 25049.507812\n",
      "New best model saved with MSE: 25049.507812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 10:   0%|          | 0/405 [00:00<?, ?it/s]/tmp/ipykernel_31/2636405055.py:37: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Retrain Epoch 10: 100%|██████████| 405/405 [01:45<00:00,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 10 Train Loss: 0.019348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 10 Val Loss: 0.044690, Unscaled MSE: 24359.527344\n",
      "New best model saved with MSE: 24359.527344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 11:   0%|          | 0/405 [00:00<?, ?it/s]/tmp/ipykernel_31/2636405055.py:37: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Retrain Epoch 11: 100%|██████████| 405/405 [01:45<00:00,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 11 Train Loss: 0.021348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 11 Val Loss: 0.053681, Unscaled MSE: 28868.271484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 12:   0%|          | 0/405 [00:00<?, ?it/s]/tmp/ipykernel_31/2636405055.py:37: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Retrain Epoch 12: 100%|██████████| 405/405 [01:45<00:00,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 12 Train Loss: 0.022080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 12 Val Loss: 0.048114, Unscaled MSE: 26465.292969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 13:   0%|          | 0/405 [00:00<?, ?it/s]/tmp/ipykernel_31/2636405055.py:37: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Retrain Epoch 13: 100%|██████████| 405/405 [01:45<00:00,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 13 Train Loss: 0.019360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 13 Val Loss: 0.041927, Unscaled MSE: 22757.236328\n",
      "New best model saved with MSE: 22757.236328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 14:   0%|          | 0/405 [00:00<?, ?it/s]/tmp/ipykernel_31/2636405055.py:37: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Retrain Epoch 14: 100%|██████████| 405/405 [01:45<00:00,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 14 Train Loss: 0.017940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 14 Val Loss: 0.044041, Unscaled MSE: 23836.271484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 15:   0%|          | 0/405 [00:00<?, ?it/s]/tmp/ipykernel_31/2636405055.py:37: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Retrain Epoch 15: 100%|██████████| 405/405 [01:45<00:00,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 15 Train Loss: 0.016570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 15 Val Loss: 0.042766, Unscaled MSE: 23037.937500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 16:   0%|          | 0/405 [00:00<?, ?it/s]/tmp/ipykernel_31/2636405055.py:37: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Retrain Epoch 16: 100%|██████████| 405/405 [01:45<00:00,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 16 Train Loss: 0.020770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 16 Val Loss: 0.046596, Unscaled MSE: 25304.138672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 17:   0%|          | 0/405 [00:00<?, ?it/s]/tmp/ipykernel_31/2636405055.py:37: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Retrain Epoch 17: 100%|██████████| 405/405 [01:45<00:00,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 17 Train Loss: 0.020016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 17 Val Loss: 0.049322, Unscaled MSE: 26713.115234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 18:   0%|          | 0/405 [00:00<?, ?it/s]/tmp/ipykernel_31/2636405055.py:37: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Retrain Epoch 18: 100%|██████████| 405/405 [01:45<00:00,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 18 Train Loss: 0.017772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 18 Val Loss: 0.051159, Unscaled MSE: 28460.939453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 19:   0%|          | 0/405 [00:00<?, ?it/s]/tmp/ipykernel_31/2636405055.py:37: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Retrain Epoch 19: 100%|██████████| 405/405 [01:45<00:00,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 19 Train Loss: 0.017593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 19 Val Loss: 0.048611, Unscaled MSE: 26569.818359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 20:   0%|          | 0/405 [00:00<?, ?it/s]/tmp/ipykernel_31/2636405055.py:37: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Retrain Epoch 20: 100%|██████████| 405/405 [01:45<00:00,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 20 Train Loss: 0.016256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrain Epoch 20 Val Loss: 0.047211, Unscaled MSE: 25936.833984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31/2636405055.py:107: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_retrained_geo2.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting CSV Generation ---\n",
      "Valid loader dataset size: 362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing validation data: 100%|██████████| 12/12 [00:05<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 362 validation images, added 362 unique IDs\n",
      "Found 369 files in test directory\n",
      "Detected 'img_' prefix in test files\n",
      "Created mapping for 369 test files\n",
      "Sample mapping: [{'filename': 'img_0000.jpg', 'image_id': 369}, {'filename': 'img_0001.jpg', 'image_id': 370}, {'filename': 'img_0002.jpg', 'image_id': 371}]\n",
      "Created test dataloader with 369 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test data: 100%|██████████| 12/12 [00:05<00:00,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 369 test images\n",
      "\n",
      "CSV saved with 731 rows:\n",
      "- 362 validation entries\n",
      "- 369 test entries\n",
      "- 0 placeholder entries for missing test IDs\n",
      "Best MSE: 22757.236328\n",
      "Retraining complete. Best MSE: 22757.236328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Improved retraining code with better LR scheduling\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, ReduceLROnPlateau\n",
    "\n",
    "# Load the previously trained model\n",
    "model.load_state_dict(torch.load('/kaggle/working/best_geo2.pth'))\n",
    "\n",
    "# Reset optimizer with lower learning rates for fine-tuning\n",
    "optimizer = optim.AdamW([\n",
    "    {'params': params_backbone, 'lr': 5e-6},  # Lower LR for backbone\n",
    "    {'params': params_new, 'lr': 1e-4}        # Lower LR for new layers\n",
    "], weight_decay=1e-3)  # Slightly reduced weight decay\n",
    "\n",
    "# Better LR scheduler - Cosine annealing with warm restarts\n",
    "scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=1, eta_min=1e-7)\n",
    "scaler = torch.cuda.amp.GradScaler() if torch.cuda.is_available() else None\n",
    "# Alternative: ReduceLROnPlateau (uncomment to use instead)\n",
    "# scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, min_lr=1e-7, verbose=True)\n",
    "\n",
    "# Number of additional training epochs\n",
    "additional_epochs = 20\n",
    "best_mse = float('inf')\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1, additional_epochs+1):\n",
    "    model.train()\n",
    "    running_loss = running_lat = running_lon = 0.0\n",
    "    count = 0\n",
    "    \n",
    "    for batch in tqdm(train_loader, desc=f\"Retrain Epoch {epoch}\"):\n",
    "        imgs = batch['image'].to(device)\n",
    "        lat_s = batch['scaled_lat'].to(device)\n",
    "        lon_s = batch['scaled_lon'].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
    "            p_lat, p_lon = model(imgs)\n",
    "            loss = criterion(p_lat, p_lon, lat_s, lon_s)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        if torch.cuda.is_available():\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        bs = imgs.size(0)\n",
    "        running_loss += loss.item() * bs\n",
    "        count += bs\n",
    "    \n",
    "    epoch_loss = running_loss / count\n",
    "    print(f\"Retrain Epoch {epoch} Train Loss: {epoch_loss:.6f}\")\n",
    "    \n",
    "    # Evaluate\n",
    "    model.eval()\n",
    "    v_loss = 0.0\n",
    "    v_count = 0\n",
    "    all_preds, all_true = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in valid_loader:\n",
    "            imgs = batch['image'].to(device)\n",
    "            lat_s = batch['scaled_lat'].to(device)\n",
    "            lon_s = batch['scaled_lon'].to(device)\n",
    "            \n",
    "            p_lat, p_lon = model(imgs)\n",
    "            loss = criterion(p_lat, p_lon, lat_s, lon_s)\n",
    "            \n",
    "            # Calculate unscaled predictions for MSE\n",
    "            ulat = lat_scaler.inverse_transform(p_lat.cpu().numpy().reshape(-1,1)).flatten()\n",
    "            ulon = long_scaler.inverse_transform(p_lon.cpu().numpy().reshape(-1,1)).flatten()\n",
    "            all_preds.append(np.vstack([ulat, ulon]).T)\n",
    "            tr_lat = batch['latitude'].numpy()\n",
    "            tr_lon = batch['longitude'].numpy()\n",
    "            all_true.append(np.vstack([tr_lat, tr_lon]).T)\n",
    "            \n",
    "            bs = imgs.size(0)\n",
    "            v_loss += loss.item() * bs\n",
    "            v_count += bs\n",
    "    \n",
    "    val_loss = v_loss / v_count\n",
    "    preds = np.concatenate(all_preds)\n",
    "    true = np.concatenate(all_true)\n",
    "    unscaled_mse = ((preds - true)**2).mean()\n",
    "    \n",
    "    print(f\"Retrain Epoch {epoch} Val Loss: {val_loss:.6f}, Unscaled MSE: {unscaled_mse:.6f}\")\n",
    "    \n",
    "    # Update scheduler (use this for ReduceLROnPlateau)\n",
    "    # scheduler.step(unscaled_mse)\n",
    "    \n",
    "    # Update scheduler (use this for CosineAnnealingWarmRestarts)\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Save best model\n",
    "    if unscaled_mse < best_mse:\n",
    "        best_mse = unscaled_mse\n",
    "        torch.save(model.state_dict(), 'best_retrained_geo2.pth')\n",
    "        print(f\"New best model saved with MSE: {best_mse:.6f}\")\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "# Load best retrained model and generate predictions\n",
    "model.load_state_dict(torch.load('best_retrained_geo2.pth'))\n",
    "generate_csv(best_mse)\n",
    "\n",
    "print(f\"Retraining complete. Best MSE: {best_mse:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final code :- angle using only images and not Region_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T12:17:46.169751Z",
     "iopub.status.busy": "2025-05-05T12:17:46.169447Z",
     "iopub.status.idle": "2025-05-05T12:52:32.113646Z",
     "shell.execute_reply": "2025-05-05T12:52:32.112909Z",
     "shell.execute_reply.started": "2025-05-05T12:17:46.169729Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31/1015802815.py:210: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda with Tesla T4\n",
      "Model: EfficientNet B0 Image-Only\n",
      "Batch Size: 96, Epochs: 60, Base LR: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60 [Train]:   0%|          | 0/68 [00:00<?, ?it/s]/tmp/ipykernel_31/1015802815.py:298: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n",
      "Epoch 1/60 [Train]: 100%|██████████| 68/68 [00:33<00:00,  2.02it/s, loss=47.6558, angle_loss=93.2566, lr=0.000080]\n",
      "Epoch 1/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.61it/s, val_loss=96.3957]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "  Train Loss: 45.1741 (Angle: 88.4477, Circle: 1.9006)\n",
      "  Val MAAE: 90.2269\n",
      "  Saved best model (MAAE: 90.2269)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/60 [Train]: 100%|██████████| 68/68 [00:33<00:00,  2.01it/s, loss=41.3328, angle_loss=80.8589, lr=0.000163]\n",
      "Epoch 2/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.57it/s, val_loss=91.1004]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/60\n",
      "  Train Loss: 41.2569 (Angle: 80.8316, Circle: 1.6822)\n",
      "  Val MAAE: 90.5432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/60 [Train]: 100%|██████████| 68/68 [00:33<00:00,  2.05it/s, loss=39.2201, angle_loss=76.8418, lr=0.000276]\n",
      "Epoch 3/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.60it/s, val_loss=97.1045]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/60\n",
      "  Train Loss: 37.6660 (Angle: 73.8294, Circle: 1.5026)\n",
      "  Val MAAE: 88.2815\n",
      "  Saved best model (MAAE: 88.2815)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/60 [Train]: 100%|██████████| 68/68 [00:33<00:00,  2.04it/s, loss=35.8647, angle_loss=70.3229, lr=0.000389]\n",
      "Epoch 4/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.61it/s, val_loss=91.0350]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/60\n",
      "  Train Loss: 34.7292 (Angle: 68.1236, Circle: 1.3349)\n",
      "  Val MAAE: 82.3251\n",
      "  Saved best model (MAAE: 82.3251)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/60 [Train]: 100%|██████████| 68/68 [00:33<00:00,  2.06it/s, loss=31.6362, angle_loss=62.0145, lr=0.000471]\n",
      "Epoch 5/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.61it/s, val_loss=81.9334]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/60\n",
      "  Train Loss: 32.5006 (Angle: 63.7585, Circle: 1.2426)\n",
      "  Val MAAE: 79.1243\n",
      "  Saved best model (MAAE: 79.1243)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/60 [Train]: 100%|██████████| 68/68 [00:33<00:00,  2.04it/s, loss=35.8391, angle_loss=70.2102, lr=0.000500]\n",
      "Epoch 7/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.48it/s, val_loss=87.5187]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/60\n",
      "  Train Loss: 27.8058 (Angle: 54.5938, Circle: 1.0178)\n",
      "  Val MAAE: 79.8383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/60 [Train]: 100%|██████████| 68/68 [00:32<00:00,  2.06it/s, loss=26.3826, angle_loss=51.8686, lr=0.000498]\n",
      "Epoch 8/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.58it/s, val_loss=87.1834]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/60\n",
      "  Train Loss: 25.8825 (Angle: 50.8454, Circle: 0.9195)\n",
      "  Val MAAE: 80.7491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/60 [Train]: 100%|██████████| 68/68 [00:32<00:00,  2.07it/s, loss=26.0094, angle_loss=51.1406, lr=0.000496]\n",
      "Epoch 9/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.63it/s, val_loss=82.7574]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/60\n",
      "  Train Loss: 24.6198 (Angle: 48.3803, Circle: 0.8593)\n",
      "  Val MAAE: 74.0406\n",
      "  Saved best model (MAAE: 74.0406)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/60 [Train]: 100%|██████████| 68/68 [00:33<00:00,  2.02it/s, loss=18.8700, angle_loss=37.1217, lr=0.000493]\n",
      "Epoch 10/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.65it/s, val_loss=71.3560]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/60\n",
      "  Train Loss: 22.8172 (Angle: 44.8516, Circle: 0.7828)\n",
      "  Val MAAE: 67.8933\n",
      "  Saved best model (MAAE: 67.8933)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/60 [Train]: 100%|██████████| 68/68 [00:33<00:00,  2.03it/s, loss=20.6200, angle_loss=40.5470, lr=0.000489]\n",
      "Epoch 11/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.62it/s, val_loss=74.6027]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/60\n",
      "  Train Loss: 21.8532 (Angle: 42.9825, Circle: 0.7239)\n",
      "  Val MAAE: 66.3289\n",
      "  Saved best model (MAAE: 66.3289)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/60 [Train]: 100%|██████████| 68/68 [00:33<00:00,  2.04it/s, loss=19.2256, angle_loss=37.8410, lr=0.000485]\n",
      "Epoch 12/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.63it/s, val_loss=76.0772]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/60\n",
      "  Train Loss: 21.1968 (Angle: 41.7035, Circle: 0.6900)\n",
      "  Val MAAE: 64.7201\n",
      "  Saved best model (MAAE: 64.7201)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/60 [Train]: 100%|██████████| 68/68 [00:32<00:00,  2.07it/s, loss=17.4922, angle_loss=34.4151, lr=0.000479]\n",
      "Epoch 13/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.61it/s, val_loss=67.4819]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/60\n",
      "  Train Loss: 19.4300 (Angle: 38.2368, Circle: 0.6232)\n",
      "  Val MAAE: 59.1580\n",
      "  Saved best model (MAAE: 59.1580)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/60 [Train]: 100%|██████████| 68/68 [00:32<00:00,  2.09it/s, loss=20.0971, angle_loss=39.4822, lr=0.000473]\n",
      "Epoch 14/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.62it/s, val_loss=62.2910]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/60\n",
      "  Train Loss: 18.2845 (Angle: 35.9996, Circle: 0.5695)\n",
      "  Val MAAE: 55.6432\n",
      "  Saved best model (MAAE: 55.6432)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/60 [Train]: 100%|██████████| 68/68 [00:33<00:00,  2.04it/s, loss=23.1690, angle_loss=45.5119, lr=0.000466]\n",
      "Epoch 15/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.63it/s, val_loss=59.0864]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/60\n",
      "  Train Loss: 17.2116 (Angle: 33.9060, Circle: 0.5172)\n",
      "  Val MAAE: 52.1176\n",
      "  Saved best model (MAAE: 52.1176)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/60 [Train]: 100%|██████████| 68/68 [00:32<00:00,  2.07it/s, loss=10.3336, angle_loss=20.4826, lr=0.000459]\n",
      "Epoch 16/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.63it/s, val_loss=47.1095]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/60\n",
      "  Train Loss: 16.0727 (Angle: 31.6818, Circle: 0.4636)\n",
      "  Val MAAE: 48.0302\n",
      "  Saved best model (MAAE: 48.0302)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/60 [Train]: 100%|██████████| 68/68 [00:32<00:00,  2.07it/s, loss=15.1039, angle_loss=29.7915, lr=0.000450]\n",
      "Epoch 17/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.61it/s, val_loss=47.2622]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/60\n",
      "  Train Loss: 15.8186 (Angle: 31.1835, Circle: 0.4537)\n",
      "  Val MAAE: 48.7463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/60 [Train]: 100%|██████████| 68/68 [00:32<00:00,  2.06it/s, loss=16.4535, angle_loss=32.4478, lr=0.000441]\n",
      "Epoch 18/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.58it/s, val_loss=50.8076]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/60\n",
      "  Train Loss: 14.8277 (Angle: 29.2454, Circle: 0.4100)\n",
      "  Val MAAE: 52.7694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/60 [Train]: 100%|██████████| 68/68 [00:32<00:00,  2.07it/s, loss=15.0118, angle_loss=29.6045, lr=0.000432]\n",
      "Epoch 19/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.24it/s, val_loss=47.2585]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/60\n",
      "  Train Loss: 14.0868 (Angle: 27.7894, Circle: 0.3842)\n",
      "  Val MAAE: 48.8718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/60 [Train]: 100%|██████████| 68/68 [00:32<00:00,  2.07it/s, loss=15.5221, angle_loss=30.6018, lr=0.000421]\n",
      "Epoch 20/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.51it/s, val_loss=39.2212]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/60\n",
      "  Train Loss: 13.3433 (Angle: 26.3305, Circle: 0.3562)\n",
      "  Val MAAE: 41.8666\n",
      "  Saved best model (MAAE: 41.8666)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/60 [Train]: 100%|██████████| 68/68 [00:32<00:00,  2.06it/s, loss=10.8795, angle_loss=21.5214, lr=0.000411]\n",
      "Epoch 21/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.63it/s, val_loss=35.4735]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/60\n",
      "  Train Loss: 13.3919 (Angle: 26.4373, Circle: 0.3464)\n",
      "  Val MAAE: 39.4482\n",
      "  Saved best model (MAAE: 39.4482)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/60 [Train]: 100%|██████████| 68/68 [00:32<00:00,  2.07it/s, loss=10.6234, angle_loss=20.9554, lr=0.000399]\n",
      "Epoch 22/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.57it/s, val_loss=38.0022]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/60\n",
      "  Train Loss: 13.4117 (Angle: 26.4721, Circle: 0.3513)\n",
      "  Val MAAE: 42.1670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/60 [Train]: 100%|██████████| 68/68 [00:33<00:00,  2.06it/s, loss=9.1587, angle_loss=18.1404, lr=0.000387] \n",
      "Epoch 23/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.61it/s, val_loss=36.8472]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/60\n",
      "  Train Loss: 11.7994 (Angle: 23.3041, Circle: 0.2948)\n",
      "  Val MAAE: 41.7416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/60 [Train]: 100%|██████████| 68/68 [00:33<00:00,  2.04it/s, loss=10.3291, angle_loss=20.4388, lr=0.000375]\n",
      "Epoch 24/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.60it/s, val_loss=33.1920]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/60\n",
      "  Train Loss: 11.3187 (Angle: 22.3586, Circle: 0.2788)\n",
      "  Val MAAE: 37.8459\n",
      "  Saved best model (MAAE: 37.8459)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/60 [Train]: 100%|██████████| 68/68 [00:33<00:00,  2.05it/s, loss=22.4987, angle_loss=44.3272, lr=0.000362]\n",
      "Epoch 25/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.63it/s, val_loss=34.8263]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/60\n",
      "  Train Loss: 11.0513 (Angle: 21.8350, Circle: 0.2675)\n",
      "  Val MAAE: 38.6658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/60 [Train]: 100%|██████████| 68/68 [00:33<00:00,  2.05it/s, loss=7.7331, angle_loss=15.3434, lr=0.000349] \n",
      "Epoch 26/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.54it/s, val_loss=31.0665]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/60\n",
      "  Train Loss: 10.2820 (Angle: 20.3236, Circle: 0.2403)\n",
      "  Val MAAE: 36.3232\n",
      "  Saved best model (MAAE: 36.3232)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/60 [Train]: 100%|██████████| 68/68 [00:32<00:00,  2.09it/s, loss=9.5151, angle_loss=18.8267, lr=0.000335] \n",
      "Epoch 27/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.62it/s, val_loss=30.9623]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/60\n",
      "  Train Loss: 10.3507 (Angle: 20.4592, Circle: 0.2422)\n",
      "  Val MAAE: 37.9068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/60 [Train]: 100%|██████████| 68/68 [00:33<00:00,  2.04it/s, loss=6.9884, angle_loss=13.8750, lr=0.000322] \n",
      "Epoch 28/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.60it/s, val_loss=27.2174]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/60\n",
      "  Train Loss: 9.9855 (Angle: 19.7440, Circle: 0.2270)\n",
      "  Val MAAE: 34.7621\n",
      "  Saved best model (MAAE: 34.7621)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/60 [Train]: 100%|██████████| 68/68 [00:32<00:00,  2.07it/s, loss=7.4522, angle_loss=14.7707, lr=0.000307] \n",
      "Epoch 29/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.68it/s, val_loss=25.8492]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/60\n",
      "  Train Loss: 10.0012 (Angle: 19.7753, Circle: 0.2270)\n",
      "  Val MAAE: 33.4927\n",
      "  Saved best model (MAAE: 33.4927)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/60 [Train]: 100%|██████████| 68/68 [00:32<00:00,  2.07it/s, loss=13.8425, angle_loss=27.1840, lr=0.000293]\n",
      "Epoch 30/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.61it/s, val_loss=26.2866]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/60\n",
      "  Train Loss: 8.9739 (Angle: 17.7501, Circle: 0.1976)\n",
      "  Val MAAE: 34.2366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/60 [Train]: 100%|██████████| 68/68 [00:32<00:00,  2.08it/s, loss=7.2895, angle_loss=14.4527, lr=0.000279] \n",
      "Epoch 31/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.64it/s, val_loss=26.3812]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/60\n",
      "  Train Loss: 8.3786 (Angle: 16.5822, Circle: 0.1750)\n",
      "  Val MAAE: 34.1375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/60 [Train]: 100%|██████████| 68/68 [00:33<00:00,  2.04it/s, loss=6.0154, angle_loss=11.9560, lr=0.000264] \n",
      "Epoch 32/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.64it/s, val_loss=24.6930]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/60\n",
      "  Train Loss: 8.6595 (Angle: 17.1356, Circle: 0.1834)\n",
      "  Val MAAE: 32.4656\n",
      "  Saved best model (MAAE: 32.4656)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/60 [Train]: 100%|██████████| 68/68 [00:32<00:00,  2.06it/s, loss=9.7122, angle_loss=19.2269, lr=0.000250] \n",
      "Epoch 33/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.27it/s, val_loss=24.1219]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/60\n",
      "  Train Loss: 8.1102 (Angle: 16.0555, Circle: 0.1648)\n",
      "  Val MAAE: 32.4749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/60 [Train]: 100%|██████████| 68/68 [00:33<00:00,  2.06it/s, loss=8.8437, angle_loss=17.5112, lr=0.000235] \n",
      "Epoch 34/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.61it/s, val_loss=23.7033]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/60\n",
      "  Train Loss: 7.4151 (Angle: 14.6884, Circle: 0.1419)\n",
      "  Val MAAE: 32.0336\n",
      "  Saved best model (MAAE: 32.0336)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/60 [Train]: 100%|██████████| 68/68 [00:33<00:00,  2.06it/s, loss=6.0978, angle_loss=12.1116, lr=0.000221] \n",
      "Epoch 35/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.53it/s, val_loss=25.4083]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/60\n",
      "  Train Loss: 7.8016 (Angle: 15.4454, Circle: 0.1577)\n",
      "  Val MAAE: 31.5983\n",
      "  Saved best model (MAAE: 31.5983)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/60 [Train]: 100%|██████████| 68/68 [00:32<00:00,  2.06it/s, loss=10.5728, angle_loss=20.9054, lr=0.000206]\n",
      "Epoch 36/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.63it/s, val_loss=25.3514]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/60\n",
      "  Train Loss: 8.2009 (Angle: 16.2335, Circle: 0.1683)\n",
      "  Val MAAE: 31.2960\n",
      "  Saved best model (MAAE: 31.2960)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/60 [Train]: 100%|██████████| 68/68 [00:33<00:00,  2.04it/s, loss=15.6646, angle_loss=30.8549, lr=0.000192]\n",
      "Epoch 37/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.58it/s, val_loss=24.0141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/60\n",
      "  Train Loss: 7.6698 (Angle: 15.1822, Circle: 0.1573)\n",
      "  Val MAAE: 31.2344\n",
      "  Saved best model (MAAE: 31.2344)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/60 [Train]: 100%|██████████| 68/68 [00:32<00:00,  2.09it/s, loss=10.1972, angle_loss=20.0752, lr=0.000178]\n",
      "Epoch 38/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.56it/s, val_loss=25.0896]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/60\n",
      "  Train Loss: 8.4913 (Angle: 16.7991, Circle: 0.1834)\n",
      "  Val MAAE: 30.6204\n",
      "  Saved best model (MAAE: 30.6204)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/60 [Train]: 100%|██████████| 68/68 [00:33<00:00,  2.05it/s, loss=6.9582, angle_loss=13.8051, lr=0.000164] \n",
      "Epoch 39/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.56it/s, val_loss=25.7476]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/60\n",
      "  Train Loss: 6.8743 (Angle: 13.6186, Circle: 0.1301)\n",
      "  Val MAAE: 30.1967\n",
      "  Saved best model (MAAE: 30.1967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/60 [Train]: 100%|██████████| 68/68 [00:32<00:00,  2.08it/s, loss=5.2556, angle_loss=10.4453, lr=0.000151] \n",
      "Epoch 40/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.53it/s, val_loss=26.9776]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/60\n",
      "  Train Loss: 5.8241 (Angle: 11.5509, Circle: 0.0973)\n",
      "  Val MAAE: 30.5645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/60 [Train]: 100%|██████████| 68/68 [00:32<00:00,  2.08it/s, loss=14.0469, angle_loss=27.7194, lr=0.000138]\n",
      "Epoch 41/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.60it/s, val_loss=26.1816]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/60\n",
      "  Train Loss: 5.6222 (Angle: 11.1502, Circle: 0.0943)\n",
      "  Val MAAE: 30.3598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/60 [Train]: 100%|██████████| 68/68 [00:33<00:00,  2.05it/s, loss=4.1206, angle_loss=8.2090, lr=0.000125]  \n",
      "Epoch 42/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.54it/s, val_loss=24.3134]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/60\n",
      "  Train Loss: 7.0039 (Angle: 13.8750, Circle: 0.1329)\n",
      "  Val MAAE: 30.5326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/60 [Train]: 100%|██████████| 68/68 [00:33<00:00,  2.04it/s, loss=4.7743, angle_loss=9.4947, lr=0.000112]  \n",
      "Epoch 43/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.61it/s, val_loss=24.4236]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/60\n",
      "  Train Loss: 6.0282 (Angle: 11.9496, Circle: 0.1069)\n",
      "  Val MAAE: 29.3808\n",
      "  Saved best model (MAAE: 29.3808)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/60 [Train]: 100%|██████████| 68/68 [00:33<00:00,  2.05it/s, loss=20.3997, angle_loss=40.1639, lr=0.000101]\n",
      "Epoch 44/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.62it/s, val_loss=23.9655]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/60\n",
      "  Train Loss: 6.8940 (Angle: 13.6548, Circle: 0.1333)\n",
      "  Val MAAE: 29.8314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/60 [Train]: 100%|██████████| 68/68 [00:32<00:00,  2.09it/s, loss=5.7809, angle_loss=11.4791, lr=0.000089] \n",
      "Epoch 45/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.61it/s, val_loss=24.3756]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/60\n",
      "  Train Loss: 6.9232 (Angle: 13.7102, Circle: 0.1362)\n",
      "  Val MAAE: 29.2214\n",
      "  Saved best model (MAAE: 29.2214)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/60 [Train]: 100%|██████████| 68/68 [00:32<00:00,  2.07it/s, loss=8.6972, angle_loss=17.1870, lr=0.000078] \n",
      "Epoch 46/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.44it/s, val_loss=24.3276]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/60\n",
      "  Train Loss: 6.9389 (Angle: 13.7382, Circle: 0.1397)\n",
      "  Val MAAE: 30.2040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/60 [Train]: 100%|██████████| 68/68 [00:33<00:00,  2.05it/s, loss=7.8051, angle_loss=15.4799, lr=0.000068] \n",
      "Epoch 47/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.62it/s, val_loss=24.7095]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/60\n",
      "  Train Loss: 6.5635 (Angle: 12.9998, Circle: 0.1272)\n",
      "  Val MAAE: 29.0273\n",
      "  Saved best model (MAAE: 29.0273)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/60 [Train]: 100%|██████████| 68/68 [00:32<00:00,  2.08it/s, loss=3.8697, angle_loss=7.7045, lr=0.000058]  \n",
      "Epoch 48/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.58it/s, val_loss=24.0946]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/60\n",
      "  Train Loss: 6.2232 (Angle: 12.3271, Circle: 0.1193)\n",
      "  Val MAAE: 28.9008\n",
      "  Saved best model (MAAE: 28.9008)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/60 [Train]: 100%|██████████| 68/68 [00:32<00:00,  2.07it/s, loss=5.2557, angle_loss=10.3958, lr=0.000049] \n",
      "Epoch 49/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.58it/s, val_loss=23.4897]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/60\n",
      "  Train Loss: 6.0028 (Angle: 11.8928, Circle: 0.1129)\n",
      "  Val MAAE: 29.8130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/60 [Train]: 100%|██████████| 68/68 [00:32<00:00,  2.08it/s, loss=6.7962, angle_loss=13.4089, lr=0.000041] \n",
      "Epoch 50/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.61it/s, val_loss=24.2816]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/60\n",
      "  Train Loss: 6.1097 (Angle: 12.1029, Circle: 0.1166)\n",
      "  Val MAAE: 29.6281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/60 [Train]: 100%|██████████| 68/68 [00:32<00:00,  2.09it/s, loss=28.2478, angle_loss=55.5473, lr=0.000033]\n",
      "Epoch 51/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.57it/s, val_loss=23.3980]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/60\n",
      "  Train Loss: 5.2991 (Angle: 10.5038, Circle: 0.0944)\n",
      "  Val MAAE: 29.9089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/60 [Train]: 100%|██████████| 68/68 [00:32<00:00,  2.09it/s, loss=4.6913, angle_loss=9.3390, lr=0.000027]  \n",
      "Epoch 52/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.58it/s, val_loss=23.4580]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/60\n",
      "  Train Loss: 5.6719 (Angle: 11.2447, Circle: 0.0990)\n",
      "  Val MAAE: 29.2683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/60 [Train]: 100%|██████████| 68/68 [00:32<00:00,  2.07it/s, loss=5.1557, angle_loss=10.2575, lr=0.000020] \n",
      "Epoch 53/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.62it/s, val_loss=23.3829]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/60\n",
      "  Train Loss: 4.5634 (Angle: 9.0585, Circle: 0.0682)\n",
      "  Val MAAE: 28.7269\n",
      "  Saved best model (MAAE: 28.7269)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/60 [Train]: 100%|██████████| 68/68 [00:34<00:00,  1.99it/s, loss=7.0336, angle_loss=13.9154, lr=0.000015] \n",
      "Epoch 54/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.59it/s, val_loss=23.4525]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/60\n",
      "  Train Loss: 4.9430 (Angle: 9.8072, Circle: 0.0788)\n",
      "  Val MAAE: 28.7971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/60 [Train]: 100%|██████████| 68/68 [00:32<00:00,  2.07it/s, loss=7.7289, angle_loss=15.2837, lr=0.000010] \n",
      "Epoch 55/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.67it/s, val_loss=23.0305]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/60\n",
      "  Train Loss: 5.6133 (Angle: 11.1278, Circle: 0.0989)\n",
      "  Val MAAE: 28.4882\n",
      "  Saved best model (MAAE: 28.4882)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/60 [Train]: 100%|██████████| 68/68 [00:36<00:00,  1.86it/s, loss=7.5578, angle_loss=14.9532, lr=0.000007] \n",
      "Epoch 56/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.49it/s, val_loss=22.9142]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/60\n",
      "  Train Loss: 4.4992 (Angle: 8.9330, Circle: 0.0654)\n",
      "  Val MAAE: 27.9167\n",
      "  Saved best model (MAAE: 27.9167)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/60 [Train]: 100%|██████████| 68/68 [00:32<00:00,  2.10it/s, loss=6.5487, angle_loss=12.9489, lr=0.000004] \n",
      "Epoch 57/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.63it/s, val_loss=22.6347]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/60\n",
      "  Train Loss: 4.9105 (Angle: 9.7400, Circle: 0.0809)\n",
      "  Val MAAE: 28.0832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/60 [Train]: 100%|██████████| 68/68 [00:32<00:00,  2.09it/s, loss=5.2121, angle_loss=10.3680, lr=0.000002] \n",
      "Epoch 58/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.63it/s, val_loss=22.6544]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/60\n",
      "  Train Loss: 5.9642 (Angle: 11.8162, Circle: 0.1123)\n",
      "  Val MAAE: 29.0653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/60 [Train]: 100%|██████████| 68/68 [00:32<00:00,  2.07it/s, loss=8.4401, angle_loss=16.6733, lr=0.000000] \n",
      "Epoch 59/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.28it/s, val_loss=22.3818]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/60\n",
      "  Train Loss: 5.1313 (Angle: 10.1734, Circle: 0.0891)\n",
      "  Val MAAE: 28.6878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/60 [Train]: 100%|██████████| 68/68 [00:32<00:00,  2.09it/s, loss=4.3060, angle_loss=8.5531, lr=0.000000]  \n",
      "Epoch 60/60 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.62it/s, val_loss=22.7880]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/60\n",
      "  Train Loss: 5.7940 (Angle: 11.4813, Circle: 0.1067)\n",
      "  Val MAAE: 27.8772\n",
      "  Saved best model (MAAE: 27.8772)\n",
      "\n",
      "Training completed!\n",
      "Best validation MAAE: 27.8772\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import timm\n",
    "import math\n",
    "import random\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "# -----------------------\n",
    "# Paths and Globals\n",
    "# -----------------------\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "BATCH_SIZE = 96     # increased batch size\n",
    "EPOCHS = 60        # more epochs\n",
    "BASE_LR = 5e-4      # higher learning rate\n",
    "WEIGHT_DECAY = 1e-4 # added weight decay\n",
    "SEED = 42           # added seed for reproducibility\n",
    "\n",
    "TRAIN_CSV = '/kaggle/input/iiith-images-latlong-smai/cleaned_data_train.csv'\n",
    "TRAIN_IMG_DIR = '/kaggle/input/iiith-images-latlong-smai/images_train/images_train/images_train/'\n",
    "VAL_CSV = '/kaggle/input/iiith-images-latlong-smai/labels_val_updated.csv'\n",
    "VAL_IMG_DIR = '/kaggle/input/iiith-images-latlong-smai/images_val/images_val/'\n",
    "MODEL_PATH = '/kaggle/working/efficientnet_angle_regressor.pt'\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "# -----------------------\n",
    "# Dataset - REMOVED Region_ID dependency\n",
    "# -----------------------\n",
    "class CampusDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None, is_val=False):\n",
    "        df = pd.read_csv(csv_file)\n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.is_val = is_val\n",
    "        if is_val:\n",
    "            self.df['idx'] = self.df.index\n",
    "        # Convert angles to radians for smoother learning\n",
    "        self.df['angle_rad'] = self.df['angle'] * (math.pi / 180.0)\n",
    "        # Create sin and cos components for circular regression - ensure float32\n",
    "        self.df['sin_angle'] = np.sin(self.df['angle_rad']).astype(np.float32)\n",
    "        self.df['cos_angle'] = np.cos(self.df['angle_rad']).astype(np.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = os.path.join(self.img_dir, row['filename'])\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        angle = float(row['angle'])\n",
    "        sin_angle = float(row['sin_angle'])\n",
    "        cos_angle = float(row['cos_angle'])\n",
    "        \n",
    "        if self.is_val:\n",
    "            return img, torch.tensor(angle, dtype=torch.float32), torch.tensor(sin_angle, dtype=torch.float32), torch.tensor(cos_angle, dtype=torch.float32), torch.tensor(int(row['idx']), dtype=torch.long)\n",
    "        return img, torch.tensor(angle, dtype=torch.float32), torch.tensor(sin_angle, dtype=torch.float32), torch.tensor(cos_angle, dtype=torch.float32)\n",
    "\n",
    "# -----------------------\n",
    "# Augmentations - Same as original\n",
    "# -----------------------\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    transforms.RandomErasing(p=0.2)\n",
    "])\n",
    "\n",
    "val_tf = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# -----------------------\n",
    "# Model: EfficientNet WITHOUT Region Conditioning\n",
    "# -----------------------\n",
    "class AngleRegressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Use EfficientNet B0 as backbone\n",
    "        self.backbone = timm.create_model('efficientnet_b0', pretrained=True, features_only=True)\n",
    "        \n",
    "        # Extract feature dimensions from the backbone\n",
    "        dummy_input = torch.zeros(1, 3, 224, 224)\n",
    "        features = self.backbone(dummy_input)\n",
    "        feature_dim = features[-1].shape[1]  # Last feature map channels\n",
    "        \n",
    "        # Global average pooling\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        # Feature processing\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Linear(feature_dim, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        \n",
    "        # Sin/Cos prediction - circular regression approach\n",
    "        self.head = nn.Linear(256, 2)\n",
    "        \n",
    "        # Enable gradient checkpointing if available\n",
    "        if hasattr(self.backbone, 'gradient_checkpointing_enable'):\n",
    "            self.backbone.gradient_checkpointing_enable()\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        x = self.global_pool(features[-1]).squeeze(-1).squeeze(-1)\n",
    "        \n",
    "        # Process features\n",
    "        x = self.features(x)\n",
    "        \n",
    "        # Predict sin and cos components\n",
    "        sin_cos = self.head(x)\n",
    "        sin_pred, cos_pred = sin_cos.split(1, dim=1)\n",
    "        \n",
    "        # Normalize the output to ensure it falls on the unit circle - ensure float32\n",
    "        norm = torch.sqrt(sin_pred**2 + cos_pred**2) + 1e-8\n",
    "        sin_norm = sin_pred / norm\n",
    "        cos_norm = cos_pred / norm\n",
    "        \n",
    "        # Convert to angle in degrees\n",
    "        angle = torch.atan2(sin_norm, cos_norm) * (180.0 / torch.tensor(math.pi, dtype=torch.float32, device=sin_pred.device))\n",
    "        # Ensure angle is in [0, 360)\n",
    "        angle = (angle + 360) % 360\n",
    "        \n",
    "        return angle.squeeze(1), sin_norm.squeeze(1), cos_norm.squeeze(1)\n",
    "\n",
    "# -----------------------\n",
    "# Loss Functions - Same as original\n",
    "# -----------------------\n",
    "def circle_loss(sin_pred, cos_pred, sin_true, cos_true):\n",
    "    # MSE loss between the normalized sin and cos components\n",
    "    return nn.MSELoss()(sin_pred, sin_true) + nn.MSELoss()(cos_pred, cos_true)\n",
    "\n",
    "def maae_loss(pred, true):\n",
    "    diff = torch.abs(pred - true)\n",
    "    return torch.mean(torch.min(diff, 360 - diff))\n",
    "\n",
    "# -----------------------\n",
    "# Mixup Implementation - Modified to remove region_id dependency\n",
    "# -----------------------\n",
    "def mixup_data(x, y_angle, y_sin, y_cos, alpha=0.2):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    lam = float(lam)  # Ensure lam is a float32 compatible value\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index]\n",
    "    \n",
    "    # We mix angles in the sin/cos space to handle the circular nature\n",
    "    mixed_sin = lam * y_sin + (1 - lam) * y_sin[index]\n",
    "    mixed_cos = lam * y_cos + (1 - lam) * y_cos[index]\n",
    "    \n",
    "    # Reconstruct angle from sin/cos - ensure torch.float32\n",
    "    mixed_angle = torch.atan2(mixed_sin, mixed_cos) * (180.0 / math.pi)\n",
    "    mixed_angle = (mixed_angle + 360) % 360\n",
    "    \n",
    "    return mixed_x, mixed_angle, mixed_sin, mixed_cos, index, lam\n",
    "\n",
    "# -----------------------\n",
    "# DataLoaders\n",
    "# -----------------------\n",
    "train_ds = CampusDataset(TRAIN_CSV, TRAIN_IMG_DIR, transform=train_tf)\n",
    "val_ds = CampusDataset(VAL_CSV, VAL_IMG_DIR, transform=val_tf, is_val=True)\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# -----------------------\n",
    "# Model, Optimizer, AMP, Scheduler\n",
    "# -----------------------\n",
    "model = AngleRegressor().to(DEVICE)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=BASE_LR, weight_decay=WEIGHT_DECAY)\n",
    "scaler = GradScaler()\n",
    "\n",
    "# OneCycleLR for faster convergence\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, \n",
    "    max_lr=BASE_LR,\n",
    "    steps_per_epoch=len(train_loader),\n",
    "    epochs=EPOCHS,\n",
    "    pct_start=0.1,\n",
    "    div_factor=10.0,\n",
    "    final_div_factor=1000.0\n",
    ")\n",
    "\n",
    "# -----------------------\n",
    "# EMA Model (Exponential Moving Average for better stability) - Same as original\n",
    "# -----------------------\n",
    "class EMA():\n",
    "    def __init__(self, model, decay=0.999):\n",
    "        self.model = model\n",
    "        self.decay = decay\n",
    "        self.shadow = {}\n",
    "        self.backup = {}\n",
    "        \n",
    "    def register(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.shadow[name] = param.data.clone()\n",
    "                \n",
    "    def update(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                assert name in self.shadow\n",
    "                new_average = self.decay * self.shadow[name] + (1.0 - self.decay) * param.data\n",
    "                self.shadow[name] = new_average.clone()\n",
    "                \n",
    "    def apply_shadow(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                assert name in self.shadow\n",
    "                self.backup[name] = param.data\n",
    "                param.data = self.shadow[name]\n",
    "                \n",
    "    def restore(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                assert name in self.backup\n",
    "                param.data = self.backup[name]\n",
    "        self.backup = {}\n",
    "\n",
    "# Initialize EMA\n",
    "ema = EMA(model, decay=0.998)\n",
    "ema.register()\n",
    "\n",
    "# -----------------------\n",
    "# Training & Validation - Modified to remove region_id dependency\n",
    "# -----------------------\n",
    "best_maae = float('inf')\n",
    "val_maae_history = []\n",
    "train_loss_history = []\n",
    "\n",
    "print(f\"Training on {DEVICE} with {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n",
    "print(f\"Model: EfficientNet B0 Image-Only\")\n",
    "print(f\"Batch Size: {BATCH_SIZE}, Epochs: {EPOCHS}, Base LR: {BASE_LR}\")\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    # Train\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_angle_loss = 0\n",
    "    train_circle_loss = 0\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch}/{EPOCHS} [Train]')\n",
    "    for imgs, angles, sin_angles, cos_angles in progress_bar:\n",
    "        imgs = imgs.to(DEVICE)\n",
    "        angles = angles.to(DEVICE)\n",
    "        sin_angles = sin_angles.to(DEVICE)\n",
    "        cos_angles = cos_angles.to(DEVICE)\n",
    "\n",
    "        # Apply mixup with 50% probability\n",
    "        if random.random() < 0.5:\n",
    "            imgs, mixed_angles, mixed_sin, mixed_cos, _, _ = mixup_data(\n",
    "                imgs, angles, sin_angles, cos_angles\n",
    "            )\n",
    "            sin_angles, cos_angles = mixed_sin, mixed_cos\n",
    "            angles = mixed_angles\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with autocast():\n",
    "            pred_angles, pred_sin, pred_cos = model(imgs)\n",
    "            \n",
    "            # Combined loss: angle MAAE + sin-cos circle loss\n",
    "            angle_loss = maae_loss(pred_angles, angles)\n",
    "            circ_loss = circle_loss(pred_sin, pred_cos, sin_angles, cos_angles)\n",
    "            loss = angle_loss * 0.5 + circ_loss * 0.5\n",
    "            \n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Update EMA model\n",
    "        ema.update()\n",
    "        \n",
    "        train_loss += loss.item() * imgs.size(0)\n",
    "        train_angle_loss += angle_loss.item() * imgs.size(0)\n",
    "        train_circle_loss += circ_loss.item() * imgs.size(0)\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\n",
    "            'loss': f\"{loss.item():.4f}\", \n",
    "            'angle_loss': f\"{angle_loss.item():.4f}\",\n",
    "            'lr': f\"{optimizer.param_groups[0]['lr']:.6f}\"\n",
    "        })\n",
    "    \n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    train_angle_loss /= len(train_loader.dataset)\n",
    "    train_circle_loss /= len(train_loader.dataset)\n",
    "    train_loss_history.append(train_loss)\n",
    "    \n",
    "    # Validate with EMA model\n",
    "    ema.apply_shadow()\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    all_preds, all_trues, all_indices = [], [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(val_loader, desc=f'Epoch {epoch}/{EPOCHS} [Val]')\n",
    "        for imgs, angles, sin_angles, cos_angles, indices in progress_bar:\n",
    "            imgs = imgs.to(DEVICE)\n",
    "            angles = angles.to(DEVICE)\n",
    "            sin_angles = sin_angles.to(DEVICE)\n",
    "            cos_angles = cos_angles.to(DEVICE)\n",
    "            \n",
    "            pred_angles, pred_sin, pred_cos = model(imgs)\n",
    "            angle_loss = maae_loss(pred_angles, angles)\n",
    "            val_loss += angle_loss.item() * imgs.size(0)\n",
    "            \n",
    "            all_preds.append(pred_angles.cpu().numpy())\n",
    "            all_trues.append(angles.cpu().numpy())\n",
    "            all_indices.append(indices.numpy())\n",
    "            \n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix({'val_loss': f\"{angle_loss.item():.4f}\"})\n",
    "    \n",
    "    # Restore original model\n",
    "    ema.restore()\n",
    "            \n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    preds = np.concatenate(all_preds)\n",
    "    trues = np.concatenate(all_trues)\n",
    "    indices = np.concatenate(all_indices)\n",
    "    \n",
    "    # Calculate MAAE (Mean Absolute Angular Error)\n",
    "    val_maae = np.mean(np.minimum(np.abs(preds-trues), 360-np.abs(preds-trues)))\n",
    "    val_maae_history.append(val_maae)\n",
    "    \n",
    "    print(f\"Epoch {epoch}/{EPOCHS}\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} (Angle: {train_angle_loss:.4f}, Circle: {train_circle_loss:.4f})\")\n",
    "    print(f\"  Val MAAE: {val_maae:.4f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_maae < best_maae:\n",
    "        best_maae = val_maae\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'ema_shadow': ema.shadow,\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_maae': val_maae,\n",
    "            'best_maae': best_maae,\n",
    "        }, MODEL_PATH)\n",
    "        print(f\"  Saved best model (MAAE: {best_maae:.4f})\")\n",
    "\n",
    "print(f\"\\nTraining completed!\")\n",
    "print(f\"Best validation MAAE: {best_maae:.4f}\")\n",
    "\n",
    "# -----------------------\n",
    "# Plot training history - Same as original\n",
    "# -----------------------\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(1, EPOCHS+1), train_loss_history, label='Train Loss')\n",
    "    plt.title('Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, EPOCHS+1), val_maae_history, label='Val MAAE')\n",
    "    plt.axhline(y=best_maae, color='r', linestyle='--', label=f'Best MAAE: {best_maae:.4f}')\n",
    "    plt.title('Validation MAAE')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MAAE (degrees)')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.close()\n",
    "except:\n",
    "    print(\"Could not generate training history plot.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting and saving in csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T13:10:31.817754Z",
     "iopub.status.busy": "2025-05-05T13:10:31.816684Z",
     "iopub.status.idle": "2025-05-05T13:10:35.542869Z",
     "shell.execute_reply": "2025-05-05T13:10:35.542019Z",
     "shell.execute_reply.started": "2025-05-05T13:10:31.817717Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31/1579367137.py:44: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(ANGLE_MODEL_PATH, map_location=DEVICE)\n",
      "Predicting: 100%|██████████| 12/12 [00:01<00:00,  7.42it/s]\n",
      "Predicting: 100%|██████████| 12/12 [00:01<00:00,  7.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved predictions to /kaggle/working/final_predictions.csv\n",
      " Val (0–368): mean=181.66, min=0.07, max=359.70\n",
      " Test (369–737): mean=187.17, min=2.69, max=359.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ---- Paths ----\n",
    "VAL_CSV       = '/kaggle/input/iiith-images-latlong-smai/labels_val_updated.csv'\n",
    "VAL_IMG_DIR   = '/kaggle/input/iiith-images-latlong-smai/images_val/images_val'\n",
    "TEST_IMG_DIR  = '/kaggle/input/iiith-images-latlong-smai/images_test/images_test'\n",
    "ANGLE_MODEL_PATH = '/kaggle/working/efficientnet_angle_regressor.pt'\n",
    "OUTPUT_CSV    = '/kaggle/working/final_predictions.csv'\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# ---- Transforms ----\n",
    "val_tf = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# ---- TestImageDataset (same) ----\n",
    "class TestImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.files = sorted(os.listdir(img_dir))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(os.path.join(self.img_dir, self.files[idx])).convert('RGB')\n",
    "        if self.transform: img = self.transform(img)\n",
    "        return img, idx\n",
    "\n",
    "# ---- Load Angle Regressor ----\n",
    "angle_model = AngleRegressor()\n",
    "ckpt = torch.load(ANGLE_MODEL_PATH, map_location=DEVICE)\n",
    "angle_model.load_state_dict(ckpt['model_state_dict'])\n",
    "angle_model.to(DEVICE).eval()\n",
    "# apply EMA if present\n",
    "if 'ema_shadow' in ckpt:\n",
    "    for n, p in angle_model.named_parameters():\n",
    "        if n in ckpt['ema_shadow']:\n",
    "            p.data = ckpt['ema_shadow'][n].clone()\n",
    "\n",
    "# ---- Dataloaders ----\n",
    "val_ds  = CampusDataset(VAL_CSV, VAL_IMG_DIR, transform=val_tf, is_val=True)\n",
    "test_ds = TestImageDataset(TEST_IMG_DIR, transform=val_tf)\n",
    "val_loader  = DataLoader(val_ds,  batch_size=32, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_ds, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "# ---- Predict Function ----\n",
    "def predict_angles(angle_model, dataloader):\n",
    "    preds = np.zeros(len(dataloader.dataset), dtype=np.float32)\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Predicting\"):\n",
    "            # Unpack img batch and index batch regardless of val vs test\n",
    "            if len(batch) == 2:\n",
    "                imgs, indices = batch               # test_loader: (img, idx)\n",
    "            else:\n",
    "                imgs, *_, indices = batch           # val_loader: (img, angle, sin, cos, idx)\n",
    "            \n",
    "            imgs = imgs.to(DEVICE)\n",
    "\n",
    "            # Predict angles\n",
    "            ang, _, _ = angle_model(imgs)\n",
    "\n",
    "            # Store into preds array\n",
    "            for i, idx in enumerate(indices):\n",
    "                preds[idx] = ang[i].item()\n",
    "    return preds\n",
    "\n",
    "# ---- Run Prediction & Save ----\n",
    "val_preds  = predict_angles(angle_model, val_loader)\n",
    "test_preds = predict_angles(angle_model, test_loader)\n",
    "\n",
    "# combine with correct indexing\n",
    "all_preds = np.concatenate([val_preds, test_preds], axis=0)\n",
    "df = pd.DataFrame({'id': np.arange(len(all_preds)), 'angle': all_preds})\n",
    "df.to_csv(OUTPUT_CSV, index=False)\n",
    "\n",
    "print(f\" Saved predictions to {OUTPUT_CSV}\")\n",
    "print(f\" Val (0–{len(val_preds)-1}): mean={val_preds.mean():.2f}, min={val_preds.min():.2f}, max={val_preds.max():.2f}\")\n",
    "print(f\" Test ({len(val_preds)}–{len(all_preds)-1}): mean={test_preds.mean():.2f}, min={test_preds.min():.2f}, max={test_preds.max():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7331338,
     "sourceId": 11681092,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
